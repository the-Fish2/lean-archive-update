[
    {
        "content": "<p>We have released two synthetic datasets containing 57k and 83k aligned data for formalized statements translated from natural language math problems. These datasets contain problems belonging to algebra, number theory and combinatorics, and are evaluated manually to ensure high accuracy. About 5k problems in Lean Workbook have searched proof based on InternLM-Math-Plus.</p>\n<p>Lean Workbook &amp; Lean Workbook Plus: <a href=\"https://huggingface.co/datasets/internlm/Lean-Workbook\">https://huggingface.co/datasets/internlm/Lean-Workbook</a></p>\n<p>Meanwhile, we open-sourced our base model and pipeline for data generation: <a href=\"https://github.com/InternLM/InternLM-Math\">https://github.com/InternLM/InternLM-Math</a></p>\n<p>We are also formalizing 21 new IMO problems by this pipeline and working on pull request to Compfiles: <a href=\"https://github.com/dwrensha/compfiles/pull/27\">https://github.com/dwrensha/compfiles/pull/27</a></p>\n<p>The arxiv-version paper of our work: <a href=\"https://arxiv.org/abs/2406.03847\">https://arxiv.org/abs/2406.03847</a></p>",
        "id": 443195465,
        "sender_full_name": "Huaiyuan Ying",
        "timestamp": 1717727896
    },
    {
        "content": "<p>Thanks so much! It's quite rare to see data like this in my opinion and I do find it interesting to see what people are using to train models</p>",
        "id": 443215023,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1717738433
    },
    {
        "content": "<p>Thanks to the authors for providing this dataset, seems like it is very large and potentially useful for the community.</p>\n<p>Given discussion in the past about how hard it is to get properly formalized data, I decided to look into whether the formalizations in the data <a href=\"https://huggingface.co/datasets/internlm/Lean-Workbook/blob/main/lean_workbook.json\">download</a> match the descriptions. I did this for 10 problems (numbers randomly selected by <a href=\"http://random.org\">random.org</a>).</p>\n<ul>\n<li>408: correct</li>\n<li>2077: correct</li>\n<li>5214: correct</li>\n<li>27195<ul>\n<li>seems to be incorrect<ul>\n<li>the variables and conditions about the values of x and y are absent.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>30705<ul>\n<li>The problem statement is of the form \"Find the maximum of this expression subject to these constraints\", but the corresponding formalization is \"Prove that any value of this expression subject to these constraints is at most 7/18\". So this suffers from the unavoidable \"<a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Meta.20IMO.20result/near/312709574\">determine</a>\" issue, as well as the avoidable-but-tricky \"maximum\" vs \"at most\" issue.</li>\n</ul>\n</li>\n<li>37823: correct</li>\n<li>38757: correct, though it is a determine statement</li>\n<li>40987<ul>\n<li>Problem statement is: Prove that for all $x \\\\ge 0, \\\\cos{x} = \\\\sin(\\\\frac{\\\\pi}{2} - x)$ and $\\\\sin{x} \\\\le x$</li>\n<li>Formalization doesn't include the second part.</li>\n<li>Also, a bit strange to have a dataset problem just be the conjuction of two theorems that are or should be in mathlib, maybe this has to do with how the database was constructed.</li>\n</ul>\n</li>\n<li>52887<ul>\n<li>seems to be incorrect:<ul>\n<li>It uses the lean expression <code>5 / 2 * (a * b + b * c + c * a)</code></li>\n<li>... when it should be <code>5 / (2 * (a * b + b * c + c * a))</code>.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>53367<ul>\n<li><del>The lean code seems like it will not compile, (not sure how this got past the \"Compiling Correctness test\" mentioned in the paper)</del> Seems maybe like these newline characters are just meant to be newline characters in the code, that makes sense<ul>\n<li><code>\\n</code> characters from the Latex problem statement are erroneously interspersed in the lean formalization.</li>\n<li>Other than that, the formalization looks correct.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>So a score of about 6 to 8 out of 10 depending on how generous you want to be. Not great, but also not terrible</p>",
        "id": 443363163,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1717789404
    },
    {
        "content": "<p>FWIW since seeing a <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270443433\">formalization error in an OpenAI blog post</a> I have never been very confident that the rates of perfectly correct formalization in these datasets are very high, kudos to the authors for their work analyzing it in section 5.</p>",
        "id": 443365003,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1717790034
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"727011\">@Huaiyuan Ying</span> , thank you for providing this dataset!</p>\n<p>I'm looking at auto-formalisation of randomly-chosen problem 27094 from Lean Workbook:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"o\">{</span><span class=\"bp\">'</span><span class=\"n\">answer'</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"bp\">''</span><span class=\"o\">,</span>\n<span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">formal_statement'</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">lean_workbook_27094</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">x</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"n\">z</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">ℝ</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">x</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">z</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"bp\">'</span>\n<span class=\"w\">                     </span><span class=\"bp\">'</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">x</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">z</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">z</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">x</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">x</span><span class=\"w\"> </span><span class=\"bp\">^</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">x</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">'</span>\n<span class=\"w\">                     </span><span class=\"bp\">'+</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"bp\">^</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">z</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">z</span><span class=\"w\"> </span><span class=\"bp\">^</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">z</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">x</span><span class=\"o\">))</span><span class=\"w\"> </span><span class=\"bp\">≥</span><span class=\"w\"> </span><span class=\"bp\">'</span>\n<span class=\"w\">                     </span><span class=\"bp\">'</span><span class=\"mi\">3</span><span class=\"w\">  </span><span class=\"o\">:=</span><span class=\"w\">  </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"gr\">sorry</span><span class=\"bp\">'</span><span class=\"o\">,</span>\n<span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">natural_language_statement'</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">prove</span><span class=\"w\"> </span><span class=\"n\">that</span><span class=\"w\"> </span><span class=\"bp\">\\\\</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"bp\">$</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">xy</span><span class=\"bp\">+</span><span class=\"n\">yz</span><span class=\"bp\">+</span><span class=\"n\">zx</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">\\\\</span><span class=\"n\">cdot</span><span class=\"w\"> </span><span class=\"bp\">\\\\</span><span class=\"n\">left</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"w\"> </span><span class=\"bp\">'</span>\n<span class=\"w\">                               </span><span class=\"bp\">'\\\\</span><span class=\"n\">frac</span><span class=\"o\">{</span><span class=\"mi\">1</span><span class=\"o\">}{</span><span class=\"n\">x</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"bp\">+</span><span class=\"mi\">2</span><span class=\"n\">xy</span><span class=\"o\">}</span><span class=\"bp\">+\\\\</span><span class=\"n\">frac</span><span class=\"o\">{</span><span class=\"mi\">1</span><span class=\"o\">}{</span><span class=\"n\">y</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"bp\">+</span><span class=\"mi\">2</span><span class=\"n\">yz</span><span class=\"o\">}</span><span class=\"bp\">+\\\\</span><span class=\"n\">frac</span><span class=\"o\">{</span><span class=\"mi\">1</span><span class=\"o\">}{</span><span class=\"n\">z</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"bp\">+</span><span class=\"mi\">2</span><span class=\"n\">zx</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"bp\">'</span>\n<span class=\"w\">                               </span><span class=\"bp\">'\\\\</span><span class=\"n\">right</span><span class=\"w\"> </span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">\\\\</span><span class=\"n\">geqslant</span><span class=\"w\"> </span><span class=\"mf\">3.</span><span class=\"bp\">$\\\\</span><span class=\"n\">n'</span><span class=\"o\">,</span>\n<span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">proof'</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"o\">[],</span>\n<span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">split'</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">lean_workbook'</span><span class=\"o\">,</span>\n<span class=\"w\"> </span><span class=\"bp\">'</span><span class=\"n\">tags'</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"bp\">'</span><span class=\"n\">inequality'</span><span class=\"o\">]}</span>\n</code></pre></div>\n<p>I'm having trouble telling if the discrepancy is due to an error in the formal statement or due to the error in the natural language statement.</p>\n<p>The difference between the two statements is that the formal statement has an extra assumption <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>∗</mo><mi>y</mi><mo>∗</mo><mi>z</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">x * y * z = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4653em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6597em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>. So the question is if the auto-formalisation model hallucinated the extra assumption, or if the OCR model that produced the natural language statement (I'm assuming that's how you do it, I'll need to check in the paper) made a transcription error.</p>\n<p>For ease of reference, here's rendered latex of the natural language problem statement:</p>\n<p><a href=\"/user_uploads/3121/Mm8nswa26ixcqfJpcYAzgUvd/Screenshot-2024-06-08-at-18.24.57.png\">Screenshot-2024-06-08-at-18.24.57.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/Mm8nswa26ixcqfJpcYAzgUvd/Screenshot-2024-06-08-at-18.24.57.png\" title=\"Screenshot-2024-06-08-at-18.24.57.png\"><img src=\"/user_uploads/3121/Mm8nswa26ixcqfJpcYAzgUvd/Screenshot-2024-06-08-at-18.24.57.png\"></a></div><p>The reason I'm asking is that I think it would be possible to crowd-source in a citizen-science fashion improvements to this dataset (if we could get 1000 participants formalising proofs of one theorem a week for a year, we could cover almost all of the Lean Workbook in a year).</p>\n<p>But I think for this we would need to be able to cross-reference the original corpus from which you sourced the natural language statements. Like in this case, it's hard to tell if the assumption  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>∗</mo><mi>y</mi><mo>∗</mo><mi>z</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">x * y * z = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4653em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6597em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span> is truly needed or not. I suspect it is not needed, as I did light numerical testing of the inequality, and it seemed like it worked even without the assumption.</p>\n<p>How hard would it be to cross-reference the original corpus from which you sourced the problems to verify correctness of the natural language statement?</p>",
        "id": 443492979,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1717864702
    },
    {
        "content": "<p>I tried to find this problem in the AoPS dataset, which I think is how you sourced it, but unfortunately I think I broke their search server, whoops :/ (It could be that using a star in a search query isn't a good idea!)</p>\n<p><a href=\"/user_uploads/3121/XoO_a1Sf3lR46NoWeGL09qHD/Screenshot-2024-06-08-at-18.49.17.png\">Screenshot-2024-06-08-at-18.49.17.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/XoO_a1Sf3lR46NoWeGL09qHD/Screenshot-2024-06-08-at-18.49.17.png\" title=\"Screenshot-2024-06-08-at-18.49.17.png\"><img src=\"/user_uploads/3121/XoO_a1Sf3lR46NoWeGL09qHD/Screenshot-2024-06-08-at-18.49.17.png\"></a></div><p>I think having a \"source\" tag in the json would be fantastic!</p>",
        "id": 443495486,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1717865442
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"111040\">Adam Kurkiewicz</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Workbook.3A.20A.20large-scale.20Lean.20formalized.20problem.20set/near/443495486\">said</a>:</p>\n<blockquote>\n<p>I tried to find this problem in the AoPS dataset, which I think is how you sourced it, but unfortunately I think I broke their search server, whoops :/ (It could be that using a star in a search query isn't a good idea!)</p>\n<p><a href=\"/user_uploads/3121/XoO_a1Sf3lR46NoWeGL09qHD/Screenshot-2024-06-08-at-18.49.17.png\">Screenshot-2024-06-08-at-18.49.17.png</a></p>\n<p>I think having a \"source\" tag in the json would be fantastic!</p>\n</blockquote>\n<p>We do not use OCR to collect natural language statements. We download the AOPS posts and use an LLM to extract its problem. So the error can come from (1) LLM extraction or (2) Autoformalization. We will work on adding a cross-reference for the Lean Workbook. Adding a cross-reference for us is not very easy though, but considering the importance we will work on it.</p>",
        "id": 443540501,
        "sender_full_name": "InternLM-Math",
        "timestamp": 1717896363
    },
    {
        "content": "<p>The inequality is homogeneous -- if you multiply all of x,y,z by 37 then it doesn't change the truth of the inequality. Hence if you know that all of x,y,z are nonzero (and the problem makes no sense if two of them are zero) then you can scale to make the product 1.</p>",
        "id": 443563224,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1717914619
    }
]