[
    {
        "content": "<p>Google Deepmind has created an AI AlphaGeometry that can solve 25 out of 30 recent geometry IMO problems: <a href=\"https://www.technologyreview.com/2024/01/17/1086722/google-deepmind-alphageometry/\">https://www.technologyreview.com/2024/01/17/1086722/google-deepmind-alphageometry/</a></p>",
        "id": 416063014,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705507513
    },
    {
        "content": "<p>Note that these are informal-to-informal proofs, although they do use some kind of domain-specific geometry language that is (semi?-)rigorous.</p>",
        "id": 416064419,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705507765
    },
    {
        "content": "<p>I got an early peek at the paper yesterday and was asked for comments. The actual paper seems to be not available on the Nature website yet.</p>",
        "id": 416064738,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705507815
    },
    {
        "content": "<p>The paper is now also online: <a href=\"https://www.nature.com/articles/s41586-023-06747-5\">https://www.nature.com/articles/s41586-023-06747-5</a> [EDIT: linkfix]</p>",
        "id": 416067713,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705508352
    },
    {
        "content": "<p>that's the same link as the one above?</p>",
        "id": 416068069,
        "sender_full_name": "David Renshaw",
        "timestamp": 1705508418
    },
    {
        "content": "<blockquote>\n<p>It completed 25 within the time limit. The previous state-of-the-art system, developed by the Chinese mathematician Wen-Tsün Wu in 1978, completed only 10.</p>\n</blockquote>\n<p>Interesting comparison between neural/statistical and <del>symbolic/mechanical</del> hybrid systems.</p>\n<blockquote>\n<p>To train AlphaGeometry's language model, the researchers had to create their own training data to compensate for the scarcity of existing geometric data. They generated nearly half a billion random geometric diagrams and fed them to the symbolic engine. This engine analyzed each diagram and produced statements about their properties. These statements were organized into 100 million synthetic proofs to train the language model.</p>\n</blockquote>\n<p>Synthetic data!</p>",
        "id": 416069818,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705508767
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243791\">David Renshaw</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416068069\">said</a>:</p>\n<blockquote>\n<p>that's the same link as the one above?</p>\n</blockquote>\n<p>fixed</p>",
        "id": 416070430,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705508889
    },
    {
        "content": "<p>Surprisingly few authors (only five). Apparently they're all from the original Google Brain (US-based) rather than DeepMind London, and this is probably done before Tony Wu left Google ...</p>\n<p>P.S. The MIT article mentions \"Thang Wang\" as a coauthor but I can only find Thang Luong in the Nature paper ...</p>",
        "id": 416072108,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705509227
    },
    {
        "content": "<blockquote>\n<p>We are open-sourcing the AlphaGeometry code and model, and hope that together with other tools and approaches in synthetic data generation and training, it helps open up new possibilities across mathematics, science, and AI.</p>\n</blockquote>\n<p><a href=\"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/\">https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</a></p>",
        "id": 416072939,
        "sender_full_name": "David Renshaw",
        "timestamp": 1705509408
    },
    {
        "content": "<blockquote>\n<p>It makes perfect sense to me now that researchers in AI are trying their hands on the IMO geometry problems first because finding solutions for them works a little bit like chess in the sense that we have a rather small number of sensible moves at every step. But I still find it stunning that they could make it work. It's an impressive achievement.</p>\n</blockquote>\n<p>Fields medalist Ngô Bảo Châu is quoted in the DeepMind blog post (which is an obvious choice as there are three Vietnamese names among the authors; the other two are Chinese names).</p>\n<p>See also: <a href=\"https://www.nytimes.com/2024/01/17/science/ai-computers-mathematics-olympiad.html\">https://www.nytimes.com/2024/01/17/science/ai-computers-mathematics-olympiad.html</a></p>\n<p>NYT back story:</p>\n<blockquote>\n<p>For four years, the computer scientist Trieu Trinh has been consumed with something of a meta-math problem: how to build an A.I. model that solves geometry problems from the International Mathematical Olympiad, the annual competition for the world’s most mathematically attuned high-school students.<br>\nLast week Dr. Trinh successfully defended his doctoral dissertation on this topic at New York University; this week, he described the result of his labors in the journal Nature.<br>\nWhile developing the project, Dr. Trinh pitched it to two research scientists at Google, and they brought him on as a resident from 2021 to 2023.<br>\nThe paper’s co-authors are Dr. Trinh’s doctoral adviser, He He, at New York University; Yuhuai Wu, known as Tony, a co-founder of xAI (formerly at Google) who in 2019 had independently started exploring a similar idea; Thang Luong, the principal investigator, and Quoc Le, both from Google DeepMind.</p>\n</blockquote>",
        "id": 416073544,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705509519
    },
    {
        "content": "<p>Haven't read it yet. I'm hoping they carefully account for data leakage.  Seeing a previous IMO problem could greatly distort the pass rate.  But other than that concern, this looks exciting.</p>",
        "id": 416080200,
        "sender_full_name": "Jason Rute",
        "timestamp": 1705511361
    },
    {
        "content": "<blockquote>\n<p>Because language models excel at identifying general patterns and relationships in data, they can quickly predict potentially useful constructs, but often lack the ability to reason rigorously or explain their decisions. Symbolic deduction engines, on the other hand, are based on formal logic and use clear rules to arrive at conclusions. They are rational and explainable, but they can be <strong>“slow” and inflexible</strong> - especially when dealing with large, complex problems on their own.</p>\n</blockquote>\n<p>Interesting characterization of symbolic methods as \"slow\". Maybe their neural guidance has become accurate enough so that less search is required, to compensate for the slowness of NN inference?</p>\n<blockquote>\n<p>Olympiad geometry problems are based on diagrams that need new geometric constructs to be added before they can be solved, such as points, lines or circles. AlphaGeometry’s language model predicts which new constructs would be most useful to add, from an infinite number of possibilities. These clues help fill in the gaps and allow the symbolic engine to make further deductions about the diagram and close in on the solution.</p>\n</blockquote>\n<p>From the example the symbolic engine processes concepts like midpoint, collinear, tangent, etc. In a sense these are APIs between the neural and symbolic parts. Should we develop / do we have parallel mathlib APIs?</p>\n<blockquote>\n<p>The symbolic engine needs definitions and deduction rules to operate. These definitions and rules are provided in two text files <a href=\"https://github.com/google-deepmind/alphageometry/blob/main/defs.txt\">defs.txt</a> and <a href=\"https://github.com/google-deepmind/alphageometry/blob/main/rules.txt\">rules.txt</a></p>\n</blockquote>\n<p>See also \"Extended Data Table 1 | List of actions to construct the random premises\" in Nature paper.</p>\n<p>Method:</p>\n<blockquote>\n<p>Humans can learn geometry using a pen and paper, examining diagrams and using existing knowledge to uncover new, more sophisticated geometric properties and relationships. Our synthetic data generation approach emulates this knowledge-building process at scale, allowing us to train AlphaGeometry from scratch, without any human demonstrations.<br>\nUsing highly parallelized computing, the system started by generating one billion random diagrams of geometric objects and exhaustively derived all the relationships between the points and lines in each diagram. AlphaGeometry found all the proofs contained in each diagram, then worked backwards to find out what additional constructs, if any, were needed to arrive at those proofs. We call this process “symbolic deduction and traceback”.</p>\n</blockquote>\n<p>Solutions are human-like:</p>\n<blockquote>\n<p>Chen said: “AlphaGeometry's output is impressive because it's both verifiable and clean. Past AI solutions to proof-based competition problems have sometimes been hit-or-miss (outputs are only correct sometimes and need human checks). AlphaGeometry doesn't have this weakness: its solutions have machine-verifiable structure. Yet despite this, its output is still human-readable. One could have imagined a computer program that solved geometry problems by brute-force coordinate systems: think pages and pages of tedious algebra calculation. AlphaGeometry is not that. It uses classical geometry rules with angles and similar triangles just as students do.”</p>\n</blockquote>\n<p>Bronze medal with geometry alone:</p>\n<blockquote>\n<p>As each Olympiad features six problems, only two of which are typically focused on geometry, AlphaGeometry can only be applied to one-third of the problems at a given Olympiad. Nevertheless, its geometry capability alone makes it the first AI model in the world capable of passing the bronze medal threshold of the IMO in 2000 and 2015.<br>\nIn geometry, our system approaches the standard of an IMO gold-medalist, but we have our eye on an even bigger prize: advancing reasoning for next-generation AI systems. Given the wider potential of training AI systems from scratch with large-scale synthetic data, this approach could shape how the AI systems of the future discover new knowledge, in math and beyond.</p>\n</blockquote>",
        "id": 416080373,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705511410
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416080200\">said</a>:</p>\n<blockquote>\n<p>Haven't read it yet. I'm hoping they carefully account for data leakage.  Seeing a previous IMO problem could greatly distort the pass rate.  But other than that concern, this looks exciting.</p>\n</blockquote>\n<p>They are touting \"train from scratch, without any human demonstrations\" ...</p>\n<blockquote>\n<p>Our synthetic data generation approach emulates this knowledge-building process at scale, allowing us to train AlphaGeometry from scratch, without any human demonstrations.</p>\n</blockquote>\n<p>I understand that the language model doesn't see any actual IMO problems, only those generated by the synthesis pipeline. However, the way the researchers designed the synthesis method may be guided by existing IMO problems.</p>",
        "id": 416080614,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705511508
    },
    {
        "content": "<p><strong>Main References</strong>: </p>\n<ul>\n<li>Nature Article: <a href=\"https://doi.org/10.1038/s41586-023-06747-5\">https://doi.org/10.1038/s41586-023-06747-5</a></li>\n<li>GitHub Repository: <a href=\"https://github.com/google-deepmind/alphageometry\">https://github.com/google-deepmind/alphageometry</a></li>\n<li>YouTube Video Explainer: <a href=\"https://youtu.be/TuZhU1CiC0k\">https://youtu.be/TuZhU1CiC0k</a><div class=\"youtube-video message_inline_image\"><a data-id=\"TuZhU1CiC0k\" href=\"https://youtu.be/TuZhU1CiC0k\"><img src=\"https://uploads.zulipusercontent.net/a006fda9b10b228b5219dd13b7f3fd7d4e660a09/68747470733a2f2f692e7974696d672e636f6d2f76692f54755a685531436943306b2f64656661756c742e6a7067\"></a></div></li>\n<li>DeepMind Blog Post: <a href=\"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/\">https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</a></li>\n</ul>",
        "id": 416086465,
        "sender_full_name": "Pietro Monticone",
        "timestamp": 1705513619
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416080200\">said</a>:</p>\n<blockquote>\n<p>Haven't read it yet. I'm hoping they carefully account for data leakage.  Seeing a previous IMO problem could greatly distort the pass rate.  But other than that concern, this looks exciting.</p>\n</blockquote>\n<p>My understanding is that they generated 100 million synthetic problems from some basic axioms, so didn't train on \"the internet\" at all.</p>",
        "id": 416088609,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1705514330
    },
    {
        "content": "<p>I wonder how the system fare against the <a href=\"https://en.wikipedia.org/wiki/Langley%27s_Adventitious_Angles\">\"adventitious angle\"</a> type of problems. Is there even a way to input numerical angles into the system?</p>",
        "id": 416093776,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705516049
    },
    {
        "content": "<p>I expect that this falls outside the scope of the problems they try to solve. Also geometric inequalities (where you have an inequality on lengths or angles in either a hypothesis or the conclusion) falls outside the scope of the problems they considered.</p>",
        "id": 416101065,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705518655
    },
    {
        "content": "<p>Actually it should be possible to describe all rational multiples of π using a combination of congruence conditions (<code>eqangle</code> in <a href=\"https://github.com/google-deepmind/alphageometry/blob/main/defs.txt#L349C1-L349C8\">defs.txt</a>, and the system certainly knows about the primitive notion <code>perp</code>, i.e. π/2). For example, <code>angle_bisector</code> and <code>trisector</code> in defs.txt are defined using this primitive notion <code>eqangle</code>. Testing out of domain generalization with problems it's not designed to solve is definitely valuable and fun!</p>",
        "id": 416103837,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705519769
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416080373\">said</a>:</p>\n<blockquote>\n<p>From the example the symbolic engine processes concepts like midpoint, collinear, tangent, etc. In a sense these are APIs between the neural and symbolic parts. Should we develop / do we have parallel mathlib APIs?</p>\n</blockquote>\n<p><a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=midpoint#doc\">docs#midpoint</a> <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Collinear#doc\">docs#Collinear</a> (both defined in an affine space context, in accordance with the usual mathlib principles of generality). We don't have a definition of tangents yet, but it would be easy to add one. (I'd suggest two definitions: one taking a <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=EuclideanGeometry.Sphere#doc\">docs#EuclideanGeometry.Sphere</a> and a point and returning the affine subspace through that point and orthogonal to the radius vector (which is the tangent space if the point is on the sphere) and one that's a predicate for an affine subspace being tangent to a sphere at a given point (the point lies on both sphere and affine subspace and the affine subspace lies inside the tangent affine subspace). When you get onto two spheres being internally or externally tangent, that adds some more definitions.)</p>",
        "id": 416331737,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705523706
    },
    {
        "content": "<p>Tangency is a case where it probably does make sense to have some specifically Euclidean definitions specifically for spheres and affine subspaces, and then later link them to concepts of tangency with more general surfaces.</p>",
        "id": 416331960,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705523792
    },
    {
        "content": "<p>I think the paper is exaggerating the difficulty of geometry formalization when it talks about \"translation difficulties unique to geometry\" or how it requires \"substantial research\". There's a large body of knowledge that needs encoding and lies outside the mainstream of undergraduate mathematics or mathematical research (hence less work done on encoding it), but not any particular difficulties unique to geometry in formalizing it.</p>",
        "id": 416332361,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705523985
    },
    {
        "content": "<p>Combinatorial geometry, on the other hand, is much closer to some mainstream research than classical Euclidean geometry is. (I still intend to formalize both aperiodic monotile papers - starting with the purely discrete and combinatorial parts which largely avoid dependencies on big pieces of theory missing from mathlib - though I don't expect to have much time for that until after IMO 2024.)</p>",
        "id": 416332997,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705524247
    },
    {
        "content": "<p>To better understand what \"combinatorial geometry\" means, I <a href=\"https://www.perplexity.ai/search/What-are-some-ljd2GyptR0SUkSGObVVLPg?s=c\">asked Perplexity</a> to give me some examples :)</p>",
        "id": 416334712,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705525069
    },
    {
        "content": "<p>I also got to read it a little early.</p>\n<p>Quick summary: I quibble a bit with both the numerator and the denominator in their topline claim (\"25/30 classical geometry IMO problems since 2000\"), and would call it more like 21/32 .... but this is still impressive!  This is a pipeline which will generally solve the easy geometry P1/P4 on an IMO.</p>\n<p>Note: pre-existing automated reasoning engines also solved 4-10 problems, which is already better than previously reported AI results on IMO problems ... so part of the work is \"just\" putting the benchmark together and trying them with appropriate computational resources.</p>\n<p><strong>Numerator quibbles:</strong><br>\nIMO 2003, problem 4 they drop one direction of an \"if and only if\"<br>\nIMO 2004, problem 5 they drop one direction of an \"if and only if\"<br>\nIMO 2005, problem 5 is an existential and they tell the bot what the witness is<br>\nIMO 2008, problem 1 they solve one of the two components of a problem and count it as a full problem</p>\n<p><strong>Denominator quibbles:</strong><br>\nUnclear why the following classical geometry problems were left out of the benchmark -- it seems plausible that they can be expressed in the restricted language:<br>\nIMO 2005, problem 1<br>\nIMO 2007, problem 2<br>\nIMO 2013, problem 3<br>\nIMO 2014, problem 3<br>\nIMO 2018, problem 6</p>",
        "id": 416337485,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1705526293
    },
    {
        "content": "<p>I see the statement: \"General-purpose formal languages such as Lean still require a large amount of groundwork to describe most IMO geometry problems at present.\" This groundwork is exactly what <span class=\"user-mention\" data-user-id=\"407577\">@André Hernández-Espiet (Rutgers)</span>'s <a href=\"https://github.com/leanprover-community/mathlib4/pull/7300\">#7300</a> is trying to accomplish...</p>",
        "id": 416337573,
        "sender_full_name": "Alex Kontorovich",
        "timestamp": 1705526335
    },
    {
        "content": "<p>One big problem with  <a href=\"https://github.com/leanprover-community/mathlib4/pull/7300\">#7300</a> is that it attempts to build all of the groundwork from scratch, without any attempt to interface with the other geometric foundations already in mathlib. This would be fine for a standalone project, but interconnectedness is really important for mathlib. I think that this is fixable without a total rewrite, but it will require some work in review.</p>",
        "id": 416338937,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1705526951
    },
    {
        "content": "<p>The geometry I set up is deliberately following the usual conventions of interconnectedness. But since mathlib covers known mathematics in general, and results such as \"these sets of axioms for geometry are equivalent\" or \"given these axioms for geometry without the parallel postulate, all models are either Euclidean or hyperbolic spaces and those do satisfy the axioms\" are certainly known mathematics (and would allow us to complete Freek theorem 12), I think it's appropriate also to have Avigad, Tarski, Hilbert, ... geometry, each following a specific set of axioms referenced to the literature rather than more interconnected, and each developing geometry at least as far as is needed to prove those consequences about how those axioms relate to geometry set up in other ways.</p>",
        "id": 416456822,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705530788
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416334712\">said</a>:</p>\n<blockquote>\n<p>To better understand what \"combinatorial geometry\" means, I <a href=\"https://www.perplexity.ai/search/What-are-some-ljd2GyptR0SUkSGObVVLPg?s=c\">asked Perplexity</a> to give me some examples :)</p>\n</blockquote>\n<p>The first example there is a shortlist problem that didn't get chosen for the IMO, as is the second. The third example starts with one sentence based on IMO 2013 problem 2, then switches to IMO 2011 problem 2. I guess that sort of thing is par for the course not just as an example of LLM output but also considering how AI papers etc. working in this area quite often make a similar mess themselves with claiming something was an IMO problem that wasn't (at least the present paper under discussion is using problems that are at worst slightly simplified versions of real IMO problems).</p>",
        "id": 416457765,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705531319
    },
    {
        "content": "<p>For genuine combinatorial geometry on the IMO, consider IMO 2020 P6, IMO 2017 P3, IMO 2015 P1, IMO 2014 P6, IMO 2013 P2, IMO 2011 P2, IMO 2006 P6, IMO 2002 P6, ... - you can argue that some of those are more like combinatorics problems with limited geometrical elements, but they are at least real IMO problems.</p>",
        "id": 416458640,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705531820
    },
    {
        "content": "<p>I wonder if we could dramatically effect the model by adjusting the sequence of letters or use unconventional naming methods. For example, use A,B,C to name the the middle of the circle, and o1, o2, o3 to name triangle. Because LLM can be easily effected by just adjusting the expressions.</p>",
        "id": 416470014,
        "sender_full_name": "Ning DY",
        "timestamp": 1705537767
    },
    {
        "content": "<p>It is my illusion or not? I feel like alphageometry construct way less auxiliary constructions to solve problems than human did, especially in complex problems like p3 or p6. For example, in 2019 p6 alphageometry only have done 2 auxiliary constructions( using one line to joint two existing points doesn’t include). So in general, alphageometry tend to use more deduction methods than constructive methods than human did?</p>",
        "id": 416487342,
        "sender_full_name": "Ning DY",
        "timestamp": 1705547798
    },
    {
        "content": "<p>I think there's something odd with the autoinformalization of their translated problem statements.</p>\n<p>Take IMO 2002 P2 as an example. This is a problem where the \"angle less than 120 degrees\" condition in the original statement was genuinely needed for the point to be the incentre rather than an excentre, and if you failed to use that condition to justify getting the incentre rather than the excentre, you got at most 6 points on that problem at the IMO. There's nothing in the translated problem statements that looks like that condition (I don't think the language used can actually express such angle inequalities), and nothing in the machine-generated solutions that looks like using it, so AlphaGeometry should not claim more than 6 points here.</p>\n<p>The supplementary information with problem statements and proofs lists IMO 2002 P2A and P2B, with no explanation of why there are two such variants or what the difference between them, or between them and the original problem, is meant to be. (I think any serious machine proving benchmark based on human olympiad problems, that's not pure informal-to-informal with original problem statements, should pay much more attention to giving detailed descriptions of the choices made in translating problems to the language read by the machine solver and how those translations are intended to differ from the original problem.)</p>\n<p>The <em>informal</em> versions of P2A and P2B in the supplementary information look very strange. P2A says \"Deﬁne point D as the circumcenter of triangle BAO.\"; for D in the original problem, that would only be true for an angle equal to 120 degrees. P2B says \"Deﬁne point E as the circumcenter of triangle BAO. Deﬁne point F as the circumcenter of triangle BAO.\", so defining both as the same point. Now, looking at <a href=\"https://github.com/google-deepmind/alphageometry/blob/main/imo_ag_30.txt\">https://github.com/google-deepmind/alphageometry/blob/main/imo_ag_30.txt</a> I don't see such issues with the statements of these two problems there (though I don't know the language being used in that file), so I suspect an autoinformalization issue. (But the issue that the solver probably isn't distinguishing the incentre from the excentres, in which case it can't get more than 6 points, seems like a real one.)</p>",
        "id": 416575781,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705586055
    },
    {
        "content": "<p>Interesting. I was already wondering exactly what language they are using, and how it deals with configurations, and whether the logic is sound. <br>\nThe paper states the following, but I don't know where to find a good source for that specialized language.</p>\n<blockquote>\n<p>To sidestep this barrier, we instead adopted a more specialized language used in GEX, JGEX, MMP, Geometer and GeoLogic</p>\n</blockquote>\n<p>It seems that the logic (or at least their version of it) is not sound, and that at least that proof makes a configuration mistake.</p>",
        "id": 416577036,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705586469
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"683869\">Caglar Gulcehre</span> has marked this topic as resolved.</p>",
        "id": 416593395,
        "sender_full_name": "Notification Bot",
        "timestamp": 1705591200
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> has marked this topic as unresolved.</p>",
        "id": 416594062,
        "sender_full_name": "Notification Bot",
        "timestamp": 1705591364
    },
    {
        "content": "<p>Hi everyone, Trieu (1st author) here. I'm responsible for collecting these problems and manual translating them to <code>imo_ag_30</code>. The supplementary PDF is generated from <code>imo_ag_30</code>, so it seems the generation of this PDF has some errors. </p>\n<p>For IMO 2002 P2, the rationale is that to prove incenter, there are two subproblems, that the point lies on each of the two bisectors, so there are 2002_2A and 2002_2B. This should reflect correctly in <code>imo_ag_30</code>.</p>\n<p>Deductive database (DD) rules cannot express inequality statements (e.g. &lt;120)., so the translated problem is proving that the point is either an incenter or excenter, which shows in the corresponding figure of the problem. </p>\n<p>A team member noticed a similar situation for IMO 2004 P1, where the translated version is about P lies on line BC, but not P between BC (an inequality). Figure 5 shows this difference between the original and translated problem.</p>\n<p>Regarding any claims that is IMO-grading related such as \"7/7 points\" or \"passing bronze medal threshold\", I tried to put extra scrutiny on them by asking human expert to evaluate (IMO 2000 and 2015 problems).  Even with that, the implied comparison to human is not perfect because the system is not taking in natural language but only a translated version. Figure 2 states this caveat and mentions that the IMO has 3 other domains. </p>\n<p>With this Figure 2, my purpose is to get an intuitive sense where alphageo is to humans, but I def think a truly fair comparison must adopt the AIMO convention.</p>\n<p>Other than that, all comparisons in the work is with other machine solvers, where they use the same problem statements and their outcome is either success/fail instead of the grading x/7.</p>\n<p>Thanks for the feedback here, I'm taking them in and revising the supplementary.</p>\n<p>edit: tbh, it is unfortunate that Fig 2 got so much focus in the press instead of Table 1 (our own doing..)<br>\nI also hope to do more analysis on the training data and will try to release it later.<br>\nI also think this youtube vid I made explain the ideas better: <a href=\"https://www.youtube.com/watch?v=TuZhU1CiC0k\">https://www.youtube.com/watch?v=TuZhU1CiC0k</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"TuZhU1CiC0k\" href=\"https://www.youtube.com/watch?v=TuZhU1CiC0k\"><img src=\"https://uploads.zulipusercontent.net/a006fda9b10b228b5219dd13b7f3fd7d4e660a09/68747470733a2f2f692e7974696d672e636f6d2f76692f54755a685531436943306b2f64656661756c742e6a7067\"></a></div><p>Thanks all for the discussions, hope to learn more from people who are olympiad expert here (I'm not qualified for the IMO)</p>",
        "id": 416600508,
        "sender_full_name": "Trieu H. Trinh",
        "timestamp": 1705593340
    },
    {
        "content": "<p>Congratulations <span class=\"user-mention\" data-user-id=\"656524\">@Trieu H. Trinh</span>: minor corrections aside, this is great work!</p>",
        "id": 416605119,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1705594700
    },
    {
        "content": "<p>Thank you for dropping by. I agree that this is truly impressive work!</p>\n<p>Is there a full description of the logic / deduction rules of the specialized language for geometry that you used?</p>",
        "id": 416608581,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1705595756
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"656524\">Trieu H. Trinh</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416600508\">said</a>:</p>\n<blockquote>\n<p>Hi everyone, Trieu (1st author) here. I'm responsible for collecting these problems and manual translating them to <code>imo_ag_30</code>. The supplementary PDF is generated from <code>imo_ag_30</code>, so it seems the generation of this PDF has some errors. </p>\n<p>For IMO 2002 P2, the rationale is that to prove incenter, there are two subproblems, that the point lies on each of the two bisectors, so there are 2002_2A and 2002_2B. This should reflect correctly in <code>imo_ag_30</code>.</p>\n<p>Deductive database (DD) rules cannot express inequality statements (e.g. &lt;120)., so the translated problem is proving that the point is either an incenter or excenter, which shows in the corresponding figure of the problem. </p>\n<p>A team member noticed a similar situation for IMO 2004 P1, where the translated version is about P lies on line BC, but not P between BC (an inequality). Figure 5 shows this difference between the original and translated problem.</p>\n<p>Regarding any claims that is IMO-grading related such as \"7/7 points\" or \"passing bronze medal threshold\", I tried to put extra scrutiny on them by asking human expert to evaluate (IMO 2000 and 2015 problems).  Even with that, the implied comparison to human is not perfect because the system is not taking in natural language but only a translated version. Figure 2 states this caveat and mentions that the IMO has 3 other domains. </p>\n<p>With this Figure 2, my purpose is to get an intuitive sense where alphageo is to humans, but I def think a truly fair comparison must adopt the AIMO convention.</p>\n<p>Other than that, all comparisons in the work is with other machine solvers, where they use the same problem statements and their outcome is either success/fail instead of the grading x/7.</p>\n<p>Thanks for the feedback here, I'm taking them in and revising the supplementary.</p>\n<p>edit: tbh, it is unfortunate that Fig 2 got so much focus in the press instead of Table 1 (our own doing..)<br>\nI also hope to do more analysis on the training data and will try to release it later.<br>\nI also think this youtube vid I made explain the ideas better: <a href=\"https://www.youtube.com/watch?v=TuZhU1CiC0k\">https://www.youtube.com/watch?v=TuZhU1CiC0k</a></p>\n<p>Thanks all for the discussions, hope to learn more from people who are olympiad expert here (I'm not qualified for the IMO)</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"656524\">@Trieu H. Trinh</span> <br>\nCongratulations to you and your team.  That is really an impress work. But I have a little question.<br>\nI have read the auxiliary constructions in supplementary informations  and compare it to the Table one. And I see the construction methods applied by machine seems to be the exactly actions to construct the random premises or their direct combinations. So does the machine did any creative or uncommon auxiliary constructions which are  unrelated to the preset actions in generating the training datas to solve the problems? Do your team find any when analysis it’s performances? Thank you.</p>",
        "id": 416614162,
        "sender_full_name": "Ning DY",
        "timestamp": 1705597655
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"656524\">Trieu H. Trinh</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416600508\">said</a>:</p>\n<blockquote>\n<p>For IMO 2002 P2, the rationale is that to prove incenter, there are two subproblems, that the point lies on each of the two bisectors, so there are 2002_2A and 2002_2B. This should reflect correctly in <code>imo_ag_30</code>.</p>\n</blockquote>\n<p>Thanks for the explanation. It would seem preferable if the language used had a concept of \"incenter_or_excenter\", at least, to allow a single problem statement to be closer to the informal statement. (My view for Lean formalizations is that it's much better to add vocabulary to mathlib to talk about the concepts used in informal IMO problem statements, than to create more artificial problem statements because of lack of vocabulary in mathlib. But then, much of the point of IMO formalizations is to help build out the associated theory in mathlib proper.)</p>\n<p>In <a href=\"https://github.com/leanprover-community/mathlib4/blob/master/Archive/Imo/Imo2019Q2.lean\">https://github.com/leanprover-community/mathlib4/blob/master/Archive/Imo/Imo2019Q2.lean</a> I included a detailed library note describing conventions for turning an informal IMO geometry problem statement into a formal Lean statement (most IMO geometry problems can't yet be stated in a natural way in Lean because they require other geometry not yet in mathlib - building up things needed for that one problem took 200 PRs). I feel it would be helpful if benchmarks generally for computer solving of mathematical problems originally set for humans, when based on a translation of the problems to some machine language (whether formal such as Lean, or a domain-specific language as in this case), came with a similarly detailed description of conventions used for the translation, along with notes for each individual problem on any further choices that needed to be made to translate it to machine language.</p>",
        "id": 416673918,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705623712
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"656524\">Trieu H. Trinh</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416600508\">said</a>:</p>\n<blockquote>\n<p>Regarding any claims that is IMO-grading related such as \"7/7 points\" or \"passing bronze medal threshold\", I tried to put extra scrutiny on them by asking human expert to evaluate (IMO 2000 and 2015 problems).  Even with that, the implied comparison to human is not perfect because the system is not taking in natural language but only a translated version. Figure 2 states this caveat and mentions that the IMO has 3 other domains. </p>\n<p>With this Figure 2, my purpose is to get an intuitive sense where alphageo is to humans, but I def think a truly fair comparison must adopt the AIMO convention.</p>\n</blockquote>\n<p>When I briefly talked to the AIMO people, I suggested that they should ask the IMO Board about publishing the mark schemes used at the IMO, so that they could be used for self-assessment by people working on AI solvers. I don't know whether they have asked the IMO Board about that, or whether the Board or Jury would be supportive of publishing mark schemes, or how many mark schemes from past IMOs could readily be collected, but personally I think that publishing mark schemes would be a good idea.</p>\n<p>(Mark schemes do accumulate case law during coordination, but just having the original scheme without such case law should be sufficient for most purposes for self-assessment of AI solutions - it would tell you whether human contestants needed to prove a particular bit of geometrical configuration information to get full marks, for example - and hopefully the AIMO grand prize would be marked by people who are actually coordinators on each problem and know the case law for it that developed while marking solutions by human contestants.)</p>",
        "id": 416675341,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705624197
    },
    {
        "content": "<p>Does anyone have thoughts of integrating this with Lean? For instance, the DSL they use can be written in Lean and hopefully generated proofs can be at least post-facto verified. Or are there some obstructions that make this hard?</p>",
        "id": 416800154,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1705677711
    },
    {
        "content": "<p>If the deductive system is sound, then the definitions and theorems could be expressed in Lean and used to convert the proofs into Lean.</p>\n<p>Being sound means, for example, that if there's ever a requirement for a nondegeneracy condition for a theorem to be true (two points need to be different, two lines need to not be parallel, three points need to not be collinear, ...), or for a construction of an extra point (or line, or circle, or ...) to be valid (two lines need to not be parallel for them to intersect, two circles or a circle and a line need to be appropriately positioned for them to intersect, ...), those conditions must be appropriately proved (or present as hypotheses in the original problem). I found that most of the Lean formalization I did of an IMO geometry problem was taken up with proving such nondegeneracy conditions, but the (informalized) proofs from AlphaGeometry in the supplementary information don't seem to contain any intermediate results of such nondegeneracy form. I don't know how AlphaGeometry avoids needing such results, or whether they are all somehow included in the DSL statements of the problems (whether or not that's properly part of the informal statement - in my formalization I gave detailed conventions for when such a nondegeneracy condition should be read as implicit in the informal statement, such as informal mathematics not referring to an angle ABC if B is equal to A or C).</p>\n<p>Of course many times human IMO contestants don't actually need to prove such conditions because they are sufficiently obvious to humans, but sometimes they do need to prove them. (IMO 2023 P6 had several places where failing to prove a nondegeneracy condition, such as that six points were not concyclic, could lose points.)</p>",
        "id": 416941109,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1705713700
    },
    {
        "content": "<p>Curious to hear if people have any ideas about any parts of math (let's say preferably with active research) where similar techniques can be applied? Thinking maybe the such an area needs to have a very limited language/set of techniques.</p>",
        "id": 417139691,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1705884869
    },
    {
        "content": "<p>I would think as a tool for research mathematics there are many cases where the similar idea of generating synthetic data for an inverse problem, training and coupling with a rule based system to verify and complete proofs should help.</p>\n<p>Indeed Francis Charton has very interesting work in this vein finding solutions of differential equations, solving recurrences and a few other things. Similarly words in free groups and/or group presentations, symbolic representations of knots/manifolds (e.g. Kirby diagrams) seem promising targets.</p>",
        "id": 417162915,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1705903032
    },
    {
        "content": "<p>To my knowledge, AlphaGeometry's logic is similar to my <a href=\"https://github.com/mirefek/geo_logic\">GeoLogic</a> in the sense that it is relying on the numerical model in topological statements. That means that its proofs cannot be translated directly to formal mathematics.</p>\n<p>On the other hand, I am somewhat interested in building a widget similar to GeoLogic for Lean, then we will need to deal with the full formalization too. There are also other unrelated issues that we would need to deal with</p>\n<ul>\n<li>To my knowledge, Lean currently doesn't have automation for angle-chasing modulo pi (equivalent to solving systems of linear equalities in a general abelian group, contrary to standard gaussian elimination, you are not allowed to divide)</li>\n<li>I am not yet sure how to do well the widget integration. The internal state of the system should be recorded (so doesn't disappear when you restart the file), it should be cached (so it doesn't need to recalculate everything every time you make a step), and it is a bit beyond a standard tactic state (it has a fast-access database of known facts about the diagram).<br>\nIn summary, would there be anyone interested actually working on making a GeoLogic-like environment for Lean? If we do this, adding AlphaGeometry suggestions / solutions on top of that should be doable.<br>\n<a href=\"/user_uploads/3121/vm8UmRIFyhiNPNjHmEpaXMDr/lean-geologic.png\">lean-geologic.png</a><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/vm8UmRIFyhiNPNjHmEpaXMDr/lean-geologic.png\" title=\"lean-geologic.png\"><img src=\"/user_uploads/3121/vm8UmRIFyhiNPNjHmEpaXMDr/lean-geologic.png\"></a></div></li>\n</ul>",
        "id": 417212910,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1705924306
    },
    {
        "content": "<blockquote>\n<p>To my knowledge, Lean currently doesn't have automation for angle-chasing modulo pi (equivalent to solving systems of linear equalities in a general abelian group, contrary to standard gaussian elimination, you are not allowed to divide)</p>\n</blockquote>\n<p>could this be done via <code>polyrith</code>?</p>",
        "id": 417214931,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1705925068
    },
    {
        "content": "<p>In a right formulation, <code>polyrith</code> succeeded</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">example</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"n\">β</span> <span class=\"n\">γ</span> <span class=\"o\">:</span> <span class=\"n\">Complex</span><span class=\"o\">)</span> <span class=\"o\">:</span>\n  <span class=\"n\">α</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span> <span class=\"bp\">→</span> <span class=\"n\">β</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span> <span class=\"bp\">→</span> <span class=\"n\">γ</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span> <span class=\"bp\">→</span> <span class=\"n\">α</span> <span class=\"bp\">=</span> <span class=\"n\">β</span> <span class=\"bp\">*</span> <span class=\"n\">γ</span> <span class=\"bp\">→</span> <span class=\"n\">β</span> <span class=\"bp\">=</span> <span class=\"n\">α</span> <span class=\"bp\">*</span> <span class=\"n\">γ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"bp\">^</span><span class=\"mi\">2</span> <span class=\"bp\">=</span> <span class=\"n\">β</span><span class=\"bp\">^</span><span class=\"mi\">2</span> <span class=\"o\">:=</span>\n<span class=\"kd\">by</span>\n  <span class=\"n\">intros</span>\n  <span class=\"n\">polyrith</span>\n</code></pre></div>\n<p>On the other hand, I want this to be something fast, running on the background every step, not something taking time and needing internet connection. And the natural formulation would be this one:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">example</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"n\">β</span> <span class=\"n\">γ</span> <span class=\"o\">:</span> <span class=\"n\">Real.Angle</span><span class=\"o\">)</span> <span class=\"o\">:</span>\n  <span class=\"n\">α</span> <span class=\"bp\">=</span> <span class=\"n\">β</span> <span class=\"bp\">+</span> <span class=\"n\">γ</span> <span class=\"bp\">→</span> <span class=\"n\">β</span> <span class=\"bp\">=</span> <span class=\"n\">α</span> <span class=\"bp\">+</span> <span class=\"n\">γ</span> <span class=\"bp\">→</span> <span class=\"mi\">2</span> <span class=\"bp\">•</span> <span class=\"n\">α</span> <span class=\"bp\">=</span> <span class=\"mi\">2</span> <span class=\"bp\">•</span> <span class=\"n\">β</span> <span class=\"o\">:=</span>\n<span class=\"kd\">by</span>\n  <span class=\"n\">intros</span>\n  <span class=\"n\">solve_abel_equations</span>\n</code></pre></div>",
        "id": 417217984,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1705926283
    },
    {
        "content": "<p><code>polyrith</code> requires a ring, not a module</p>",
        "id": 417218332,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1705926391
    },
    {
        "content": "<blockquote>\n<p>not something taking time and needing internet connection</p>\n</blockquote>\n<p>Making polyrith run locally would be straightforward, but asking new lean users to install sage instead would not be</p>",
        "id": 417218435,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1705926433
    },
    {
        "content": "<p>If it is possible to ask lean users to install npm... <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> . But I also prefer less crazy dependencies.</p>",
        "id": 417221905,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1705927614
    },
    {
        "content": "<p>And I am not sure how well the <code>polyrith</code> scales since angle-chasing is in principle much easier task than solving polynomial equations.</p>",
        "id": 417222300,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1705927740
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/417139691\">said</a>:</p>\n<blockquote>\n<p>Curious to hear if people have any ideas about any parts of math (let's say preferably with active research) where similar techniques can be applied? Thinking maybe the such an area needs to have a very limited language/set of techniques.</p>\n</blockquote>\n<p>I think this is the most important follow up question to this work.  I haven’t looked at the paper in great detail, but from the explainer video I think it comes down to the following properties:</p>\n<ol>\n<li>They have a formal system for checking solutions in this area of math.</li>\n<li>They have an efficient way to generate millions of problems and their solutions.</li>\n<li>The solutions often contain extra information (like a reference to a midpoint of some line segment) that is very useful for the proofs but not needed to state the problem.  They have an automatic way to find that extra information, so they can remove it from the problem statements.</li>\n<li>They can train a model to predict this auxiliary information.</li>\n</ol>\n<p>I think many areas of math could possibly fit into this paradigm, but it might take some work to put it into that form.  We have already seen work done using somewhat similar approaches for <a href=\"https://arxiv.org/abs/1912.01412\">symbolic integration</a>.  In the integration work the auxiliary information they tried to predict is the final integral.  After that, checking the solution is largely routine with automatic symbolic differentiation and equality checking.</p>",
        "id": 417226753,
        "sender_full_name": "Jason Rute",
        "timestamp": 1705929380
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133339\">Mirek Olšák</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/417222300\">said</a>:</p>\n<blockquote>\n<p>And I am not sure how well the <code>polyrith</code> scales since angle-chasing is in principle much easier task than solving polynomial equations.</p>\n</blockquote>\n<p>it's seemed pretty fast most times I've used it, I just worry there's no need to reinvent the wheel</p>",
        "id": 417229981,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1705930500
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"111080\">Floris van Doorn</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416577036\">said</a>:</p>\n<blockquote>\n<p>Interesting. I was already wondering exactly what language they are using, and how it deals with configurations, and whether the logic is sound. <br>\nThe paper states the following, but I don't know where to find a good source for that specialized language.</p>\n<blockquote>\n<p>To sidestep this barrier, we instead adopted a more specialized language used in GEX, JGEX, MMP, Geometer and GeoLogic</p>\n</blockquote>\n<p>It seems that the logic (or at least their version of it) is not sound, and that at least that proof makes a configuration mistake.</p>\n</blockquote>\n<p>In JGEX, MMP Geometer there is no logic, or language for proofs, only a langage for describing statements (some geometric predicates mainly).</p>",
        "id": 417231189,
        "sender_full_name": "Julien Narboux",
        "timestamp": 1705930947
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/416941109\">said</a>:</p>\n<blockquote>\n<p>If the deductive system is sound, then the definitions and theorems could be expressed in Lean and used to convert the proofs into Lean.</p>\n<p>Being sound means, for example, that if there's ever a requirement for a nondegeneracy condition for a theorem to be true (two points need to be different, two lines need to not be parallel, three points need to not be collinear, ...), or for a construction of an extra point (or line, or circle, or ...) to be valid (two lines need to not be parallel for them to intersect, two circles or a circle and a line need to be appropriately positioned for them to intersect, ...), those conditions must be appropriately proved (or present as hypotheses in the original problem). I found that most of the Lean formalization I did of an IMO geometry problem was taken up with proving such nondegeneracy conditions, but the (informalized) proofs from AlphaGeometry in the supplementary information don't seem to contain any intermediate results of such nondegeneracy form. I don't know how AlphaGeometry avoids needing such results, or whether they are all somehow included in the DSL statements of the problems (whether or not that's properly part of the informal statement - in my formalization I gave detailed conventions for when such a nondegeneracy condition should be read as implicit in the informal statement, such as informal mathematics not referring to an angle ABC if B is equal to A or C).</p>\n<p>Of course many times human IMO contestants don't actually need to prove such conditions because they are sufficiently obvious to humans, but sometimes they do need to prove them. (IMO 2023 P6 had several places where failing to prove a nondegeneracy condition, such as that six points were not concyclic, could lose points.)</p>\n</blockquote>\n<p>I have exactly the same question. For example line 7 of <a href=\"https://github.com/google-deepmind/alphageometry/blob/main/rules.txt\">https://github.com/google-deepmind/alphageometry/blob/main/rules.txt</a> you have the midpoint theorem : midp E A B, midp F A C =&gt; para E F B C this should assume that B is different from C. I guess one assume somehow that points are in general position in the statement of the problem, but  one should also prove the ndgs for the constructed points, and this can lead to proof by case distinctions. <span class=\"user-mention\" data-user-id=\"656524\">@Trieu H. Trinh</span>  do you deal with the non degeneracy conditions ?</p>",
        "id": 417232841,
        "sender_full_name": "Julien Narboux",
        "timestamp": 1705931490
    },
    {
        "content": "<p>Congratulations to <span class=\"user-mention\" data-user-id=\"656524\">@Trieu H. Trinh</span> it is a very interesting paper, the contribution is not only the machine learning part but also the extension of the deductive database method.</p>",
        "id": 417239923,
        "sender_full_name": "Julien Narboux",
        "timestamp": 1705933483
    },
    {
        "content": "<p>I wonder which implementation did you use to compare with Wu's method. Are you a version in a modern computer algebra system ? I think it may have an impact because polynomial computations have progressed a lot since the days Dongming Wang had an implementation <a href=\"https://wang.cc4cm.org/epsilon/\">https://wang.cc4cm.org/epsilon/</a> but I don't know if it works with modern maple.</p>",
        "id": 417242010,
        "sender_full_name": "Julien Narboux",
        "timestamp": 1705934049
    },
    {
        "content": "<p><a href=\"https://www.nature.com/articles/s41586-023-06747-5#Sec8\">The paper</a> says:</p>\n<blockquote>\n<p>Geometry theorem provers in the literature fall into two categories. The first category is computer algebra methods, which treats geometry statements as polynomial equations of its point coordinates. Proving is accomplished with specialized transformations of large polynomials. <strong>Gröbner bases and Wu’s method</strong> are representative approaches in this category, ... Because these methods often have large time and memory complexity, especially when processing IMO-sized problems, we report their result by assigning success to any problem that can be decided within 48 h using <strong>one of their existing implementations [17]</strong>. AlphaGeometry belongs to the second category of solvers, often described as search/axiomatic or sometimes ‘synthetic’ methods. </p>\n</blockquote>\n<p>where [17] is the <a href=\"https://link.springer.com/chapter/10.1007/978-3-642-21046-4_10\">JGEX paper</a>, which says:</p>\n<blockquote>\n<p><strong>The Proving and Reasoning Part.</strong> Beside the traditional algebraic methods such as Wu’s method and the Gröbner basis method, we have also implemented the full-angle method and the deductive database method [3,6] for generating short, elegant synthetic proofs.</p>\n</blockquote>\n<p>Notice that the same volume includes a paper co-authored by Dongming Wang which mentions Epsilon.</p>",
        "id": 417269998,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1705941366
    },
    {
        "content": "<p>I have been trawling through the source and have questions I am asking here because I do not know where else to ask. There are relations <code>simtri*</code> and <code>contri*</code> which are variants of <code>simtri</code> (similar triangles) and <code>contri</code> (congruent triangles). But I cannot figure out the difference, i.e., why the star.</p>",
        "id": 422800576,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1708602849
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry/near/422800576\">said</a>:</p>\n<blockquote>\n<p>I have been trawling through the source and have questions I am asking here because I do not know where else to ask. There are relations <code>simtri*</code> and <code>contri*</code> which are variants of <code>simtri</code> (similar triangles) and <code>contri</code> (congruent triangles). But I cannot figure out the difference, i.e., why the star.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"240875\">@Yuhuai Tony Wu</span> could you clarify (I believe you are an author)?</p>",
        "id": 422803800,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1708604046
    },
    {
        "content": "<p>Tony once told me he doesn’t check this Zulip often (even when DMed).  But <span class=\"user-mention\" data-user-id=\"656524\">@Trieu H. Trinh</span> seems to have already answered some questions about the paper, so he might be willing to answer this one.</p>",
        "id": 422807946,
        "sender_full_name": "Jason Rute",
        "timestamp": 1708605596
    },
    {
        "content": "<p>On <time datetime=\"2024-03-20T18:00:00Z\">2024-03-20T14:00:00-04:00</time>, Trieu H. Trinh will speak on </p>\n<p><strong>Solving olympiad geometry without human demonstrations</strong></p>\n<p><a href=\"/user_uploads/3121/MsGc9_xjevI1wQaVesgrp0fL/image.png\">image.png</a><br>\n<a href=\"https://cmsa.fas.harvard.edu/event/nt-32024/\">https://cmsa.fas.harvard.edu/event/nt-32024/</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/MsGc9_xjevI1wQaVesgrp0fL/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/MsGc9_xjevI1wQaVesgrp0fL/image.png\"></a></div><p>Trieu will speak on AlphaGeometry, the state of the art neurosymbolic theorem proving system which can solve International Mathematical Olympiad level problems with performance approaching that of an IMO gold medalist.</p>",
        "id": 426407330,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1710356208
    },
    {
        "content": "<p>Warning for those unwise enough to look at the poster time rather than the time zone-specific time Junyan posted: we're at that funny time of year when the Americans have put their clocks forward but the Europeans still haven't, so NYC is only 4 hours off London time right now, and only 5 off CET.</p>",
        "id": 426438707,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1710369604
    }
]