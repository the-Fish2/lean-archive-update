[
    {
        "content": "<p>Moving these messages from <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover\">#Machine Learning for Theorem Proving &gt; DeepSeek-Prover</a>.</p>",
        "id": 447028458,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719361931
    },
    {
        "content": "<p>Don't think I can move them.  I'll just quote them...</p>",
        "id": 447028961,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719362169
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115180\">Qian Hong</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover/near/440839163\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover/near/440533137\">said</a>:</p>\n<blockquote>\n<p>Josef Urban likes to claim that automated methods can solve say 80% of Mizar theorems.  (If someone could remind me where to find this reference that would be great.)  </p>\n</blockquote>\n<p><a href=\"https://intelligence.org/2013/12/21/josef-urban-on-machine-learning-and-automated-reasoning/\">https://intelligence.org/2013/12/21/josef-urban-on-machine-learning-and-automated-reasoning/</a></p>\n</blockquote>",
        "id": 447028969,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719362174
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover/near/440907547\">said</a>:</p>\n<blockquote>\n<p>This accords with my recollection: Josef did not say 80% now, he said <a href=\"https://arxiv.org/abs/2303.06686\">60% now</a> and 80% in 10 years (20 from the date of that interview)</p>\n</blockquote>",
        "id": 447029031,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719362199
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover/near/441025986\">said</a>:</p>\n<blockquote>\n<p>Thanks <span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> .  I misremembered. But I’m actually referring to the <strong>75%</strong> number in that paper which is also the number on <a href=\"https://github.com/ai4reason/ATP_Proofs\">this website</a>.  In that number he is combining many different solvers.  If we did the same for MiniF2F, Mathlib, or Isabelle/HOL AFP (through the PISA benchmark) we would also probably see really high pass rates.  (Heck, even in our <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac paper</a> if we combine <em>all</em> 25 solvers we benchmarked at some point on the test set, we get a combined 50% pass rate, almost twice the pass rate of our best single method.  Of course this naive combining requires x25 more compute than the single best method.)</p>\n</blockquote>",
        "id": 447029070,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719362225
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306713\">Lasse Blaauwbroek</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover/near/441738576\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover/near/441025986\">said</a>:</p>\n<blockquote>\n<p>I misremembered. But I’m actually referring to the <strong>75%</strong> number in that paper which is also the number on <a href=\"https://github.com/ai4reason/ATP_Proofs\">this website</a>.</p>\n</blockquote>\n<p>Note that this number is obtained by using human-supplied premises. As such, these proofs are not found fully autonomously. A bit further down on the website, it reports 58% proof rate while using trained premise selectors.</p>\n</blockquote>",
        "id": 447029238,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719362304
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"223577\">@Josef Urban</span> sent me the following detailed response over email (edited and posted here with his permission):</p>\n<blockquote>\n<ol>\n<li>\n<p>I did announce in 2021 that AI/TP methods could solve 75% of Mizar when helped by human premise selection [1].</p>\n</li>\n<li>\n<p>I announced in my 2021 final ERC report [2] and later in the 2023 Mizar60 ITP paper [3,4] that AI/TP methods could solve 58.4% (\"about 60%\") fully automatically (i.e., in the hammer/chainy mode) when using a total CPU limit of 420s.</p>\n</li>\n<li>\n<p>The evaluations that use CPU-time-limited portfolio go way back at least to the Mizar40 [5] and AR-for-Flyspeck [6] papers. They are also regularly used in hammer evaluations, ATP competitions like CASC, etc. Doing strategy and system combinations within an allowed CPU limit has been one of the major weapons in the ATP domain since the time of Tammet's Gandalf. I even started a series of systems in 2012 (BliStr [7]) that evolve complementary strategies. It's a nice AI research area of its own today (sadly, mostly escaping the DL/LLM-blindsided people).</p>\n</li>\n<li>\n<p>In [2-6], we are usually pretty clear that there is no time limit applied to the total number of problems solved (75% recently and 56% in Mizar40). It's just an interesting number saying: In all of our attempts (which also use human premises), we could solve this many problems. We could try to construct a time-limited portfolio for this, but we were typically too exhausted by doing it for the hammer/chainy mode.</p>\n</li>\n<li>\n<p>I did mention 80% in the hammer/chainy mode (and using the same HW resources as before, i.e. 420 s) in my 2013 MIRI interview [8], and then put it as one of the challenges and bets in my 2014 IHP talk [9]. I guess I do \"like\" to mention these challenges/bets [10]. Maybe because they come from a time when almost nobody was doing ML for TP, there was no money and AI millionaires in it, and I was crazy enough to attach quite a bit of my \"poor Dutch postdoc\" money to the bets. But that's very different from claiming that we have done them. The 80% bet comes up in 2034 and anybody can still bet me.</p>\n</li>\n<li>\n<p>As a matter of fact, the 75% total number has been very recently increased to 80% just by using cvc5 in interesting ways. The paper was posted on arxiv this week [11].</p>\n</li>\n</ol>\n<p>[1]: <a href=\"https://github.com/ai4reason/ATP_Proofs/blob/master/75percent_announce.md\">https://github.com/ai4reason/ATP_Proofs/blob/master/75percent_announce.md</a> <br>\n[2]: <a href=\"http://ai4reason.org/PR_CORE_SCIENTIFIC_4.pdf\">http://ai4reason.org/PR_CORE_SCIENTIFIC_4.pdf</a><br>\n[3]: <a href=\"https://doi.org/10.48550/arXiv.2303.06686\">https://doi.org/10.48550/arXiv.2303.06686</a><br>\n[4]: <a href=\"https://doi.org/10.4230/LIPIcs.ITP.2023.19\">https://doi.org/10.4230/LIPIcs.ITP.2023.19</a><br>\n[5]: <a href=\"https://doi.org/10.1007/s10817-015-9330-8\">https://doi.org/10.1007/s10817-015-9330-8</a><br>\n[6]: <a href=\"https://doi.org/10.1007/s10817-014-9303-3\">https://doi.org/10.1007/s10817-014-9303-3</a><br>\n[7]: <a href=\"http://arxiv.org/abs/1301.2683\">http://arxiv.org/abs/1301.2683</a><br>\n[8]: <a href=\"http://intelligence.org/2013/12/21/josef-urban-on-machine-learning-and-automated-reasoning/\">http://intelligence.org/2013/12/21/josef-urban-on-machine-learning-and-automated-reasoning/</a><br>\n[9]: <a href=\"https://www.ciirc.cvut.cz/~urbanjo3/ihp14/ihp14.html\">https://www.ciirc.cvut.cz/~urbanjo3/ihp14/ihp14.html</a><br>\n[10]: <a href=\"http://ai4reason.org/aichallenges.html\">http://ai4reason.org/aichallenges.html</a><br>\n[11]: <a href=\"https://arxiv.org/abs/2406.17762\">https://arxiv.org/abs/2406.17762</a></p>\n</blockquote>",
        "id": 447463349,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719490776
    },
    {
        "content": "<p>The more I think about it, the more I agree it is a forgotten fact in the DL/LLM world that diversity of approaches helps so much.  If aliens attacked us and demanded we submit a computer program solving as many theorems as possible, it would almost certainly be the best idea to throw in as many solvers as possible.  This might be more true of theorem proving more than most other applications of ML research since there is an obvious way to combine two solvers: run one and if it doesn't solve the problem, then run the other.  (Of course, smart routing and scheduling of the various solvers would be even better as Josef says.)</p>",
        "id": 447472277,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719493211
    },
    {
        "content": "<p>I still wonder what this realization means for benchmarks like MiniF2F, PISA, and the new ones coming out.  If one really wants to get SoTA, then it would be best to union all known approaches.  The danger is that this isn't too interesting unless it is done in an interesting and generalizable way, and I think many of us would hope (maybe naively) for more general single solutions that can replace the hodgepodge of existing approaches.</p>",
        "id": 447472305,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719493217
    },
    {
        "content": "<p>Here are a few follow-up questions for <span class=\"user-mention\" data-user-id=\"223577\">@Josef Urban</span>:</p>\n<ol>\n<li>What do you think is a reasonable ballpark estimate of the percent of Mizar theorems that could be solved in a “reasonable time” given a smart strategy combining existing solvers?  (“Reasonable time” is relative, of course, especially given that computers are getting faster and GPUs are more and more commonplace.)  I would be interested in either the setting with or without human-selected premises.</li>\n<li>Do you have detailed information on which solvers solved which theorems?  I could see that data being very interesting to look into.</li>\n<li>Do your numbers on the <a href=\"https://github.com/ai4reason/ATP_Proofs\">ATP Proofs</a> site include work outside your group?  In particular, I’m thinking about <a href=\"https://github.com/IBM/TRAIL\">TRAIL</a> by my colleagues at IBM Research, especially their <a href=\"https://arxiv.org/abs/2305.08676\">newest paper</a>.  It is an RL approach, just like your <a href=\"https://papers.nips.cc/paper_files/paper/2018/file/55acf8539596d25624059980986aaa78-Paper.pdf\">RL of TP</a> paper and <a href=\"https://arxiv.org/abs/2112.10664\">DeepMind’s Incremental Learning paper</a> (which unfortunately only tests on TPTP).  Actually, I’m not sure if you included any RL results, including your own, on the ATP Proofs site.  If so, I would be curious why.</li>\n</ol>",
        "id": 447475308,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719494115
    },
    {
        "content": "<p>Actually, I think I have a slightly better idea about question 3.  It looks like your rlCop and plCop, Deepmind's IL w/ HER, and IBM's TRAIL and NIAGRA test on a smaller subset of the Mizar dataset, with about 2k problems.  (I found the IL w/ HER results for Mizar in <a href=\"https://aitp-conference.org/2022/abstract/AITP_2022_paper_9.pdf\">their ATP report</a>.)  There appear to be two such 2000 problem datasets, MPTP2078 and M2k, where M2k is much easier since it includes only problems already solvable by an ATP.  I also assume both test sets include human premises making them easier.</p>",
        "id": 447541836,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719510921
    },
    {
        "content": "<p>So I guess these methods can't be counted in the above 75% since they don't cover the whole Mizar library like the results in the ATP Proofs website.</p>",
        "id": 447541853,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719510926
    },
    {
        "content": "<p>Nonetheless, it is interesting to point out that the best methods on MPTP2078, including both Vampire and the best RL methods, each get close to 75% alone.  (See Table 2 in the <a href=\"https://arxiv.org/pdf/2305.08676\">NIAGRA paper</a> for a full summary of current results.)  Of course, this might be using more compute than any of the approaches listed on the ATP Proofs website.   (Also RL is a multiple-problems-at-a-time approach instead of a one-problem-at-a-time approach).  I wonder how all the results in Table 2 do when combined.  The combination must easily be approaching over 80% (again in the easy-mode setting of using human-premises).</p>",
        "id": 447542098,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719510967
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/GDROH-GNxky3ugMf9kM4hyw5/Screen-Shot-2024-06-27-at-2.02.59-PM.png\">Screen-Shot-2024-06-27-at-2.02.59-PM.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/GDROH-GNxky3ugMf9kM4hyw5/Screen-Shot-2024-06-27-at-2.02.59-PM.png\" title=\"Screen-Shot-2024-06-27-at-2.02.59-PM.png\"><img src=\"/user_uploads/3121/GDROH-GNxky3ugMf9kM4hyw5/Screen-Shot-2024-06-27-at-2.02.59-PM.png\"></a></div>",
        "id": 447544146,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719511345
    }
]