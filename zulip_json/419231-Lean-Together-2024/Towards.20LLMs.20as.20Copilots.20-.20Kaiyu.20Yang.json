[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"315577\">@Mac Malone</span> just noting a hidden lake feature request from the talk: the LeanCopilot readme asks that you add link arguments to the downstream project, it should be possible for the upstream project to be able to do this directly</p>",
        "id": 412375493,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1704989462
    },
    {
        "content": "<p>I have a broad question here! <span class=\"user-mention\" data-user-id=\"260507\">@Heather Macbeth</span> has made the point that LLM-based tactic search is only as good as the underlying tactic language. The symbolic methods used by normal tactics are the building blocks for any kind of copilot and improving these improves the copilot. But our current tactic suite is designed around humans, it's not necessarily the best tactics for human use are also the best tactic for LLMs (at least if you're interested in generating full proofs). Has anyone thought about what AI-oriented symbolic tactics might look like?</p>",
        "id": 412380815,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1704991106
    },
    {
        "content": "<p>I have two questions, very broad as well:<br>\nI’m somewhat surprised that the same textual representation of the proof state that we humans use is also best for the machine model. Why not something that makes some of implicit structure more easily “machine” readable, e.g. using S-Expressions, adding more contextual information, maybe alpha-renaming to reduce irrelevant variation. <br>\nOr is it the case that seeing through these things is so simple for LLMs these days that there isn’t much to be gained?</p>",
        "id": 412382734,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1704991755
    },
    {
        "content": "<p>And the other one is about attack surface. The copilot runs arbitrary tactics, behind the scenes, without user interaction. A malicious tactic could take over the user's machine, right? So if someone were to train the model on, say, all of reservoir, it seem it wouldn’t be too hard to poison it to try some some malicious tactics. How do Copilot-like systems prevent that so far?</p>",
        "id": 412382998,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1704991837
    },
    {
        "content": "<p>S-Expressions of lean expressions end up being really huge, right (by which I mean when compared with something like the pretty printed expression)?</p>",
        "id": 412383174,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1704991904
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412382734\">said</a>:</p>\n<blockquote>\n<p>I’m somewhat surprised that the same textual representation of the proof state that we humans use ...</p>\n</blockquote>\n<p>In particular I'd claim that this is <em>not</em> what we humans use, and we regular use additional information accessible via hovers in the editor and infoview</p>",
        "id": 412385523,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704992582
    },
    {
        "content": "<p>Maybe someone should ping <span class=\"user-mention\" data-user-id=\"254430\">@Kaiyu Yang</span>  about this thread :-)</p>",
        "id": 412386484,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1704992881
    },
    {
        "content": "<p>There are attempts using more machine-oriented representation of states. E.g., [ASTactic] (<a href=\"https://arxiv.org/abs/1905.09381\">https://arxiv.org/abs/1905.09381</a>) and its follow-up works use the ASTs of terms in the form of S-expressions. <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a> uses GNNs to encode the graph of terms. We don't really have enough empirical evidence to know how these non-LLM methods compare to LLM-based methods such as ours, due to difficulties in a fair comparison across different proof assistants.</p>\n<p>Nevertheless, I tend to believe it's better for LLM-based methods to take human-readable input formats such as pretty-printed tactic states. These models are pretrained on natural language from the web and programs (in Python, C++, etc.) from GitHub. It's likely that what they have learned can be better transferred to domains with similar human-readable representations.</p>",
        "id": 412392354,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1704995019
    },
    {
        "content": "<p>Furthermore, a promising approach (that we haven't explored yet) is to use LLMs to learn to align informal and formal math (see <a href=\"https://arxiv.org/abs/2210.12283\">Draft, Sketch, and Prove</a>). LLMs' are likely needed for this setup, given their capabilities in understanding/generating natural language.</p>",
        "id": 412392654,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1704995135
    },
    {
        "content": "<p>I just tried to add this copilot to the repo for the course which I started teaching today <a href=\"https://github.com/ImperialCollegeLondon/formalising-mathematics-2024\">https://github.com/ImperialCollegeLondon/formalising-mathematics-2024</a> (a project which depends on <code>mathlib</code>) and to my surprise <code>lake update LeanCopilot</code> seemed to update <code>std</code>, and now <code>lake exe cache get</code> followed by <code>lake build</code> is building <code>Std</code>. Is this expected?</p>",
        "id": 412393203,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704995346
    },
    {
        "content": "<p>Sounds like some version mismatch between the std in the two dependencies?</p>",
        "id": 412393319,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1704995398
    },
    {
        "content": "<p>What does <code>git diff</code> show?</p>",
        "id": 412393415,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704995424
    },
    {
        "content": "<p>If it modified the <code>Std</code> version in the lake-manifest, then Adam is probably correct (and the fix is to revert that change with <code>git checkout -p HEAD lake-manifest.json</code>)</p>",
        "id": 412393486,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704995459
    },
    {
        "content": "<p>How heavily does LeanCopilot depend on <code>std</code> <span class=\"user-mention\" data-user-id=\"584504\">@Kaiyu Yang</span> ?</p>",
        "id": 412393569,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1704995497
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412393415\">said</a>:</p>\n<blockquote>\n<p>What does <code>git diff</code> show?</p>\n</blockquote>\n<div class=\"codehilite\" data-code-language=\"Text only\"><pre><span></span><code>--- a/lake-manifest.json\n+++ b/lake-manifest.json\n@@ -4,26 +4,35 @@\n  [{\"url\": \"https://github.com/leanprover/std4\",\n    \"type\": \"git\",\n    \"subDir\": null,\n-   \"rev\": \"d8610e1bcb91c013c3d868821c0ef28bf693be07\",\n+   \"rev\": \"ee49cf8fada1bf5a15592c399a925c401848227f\",\n    \"name\": \"std\",\n...\n</code></pre></div>",
        "id": 412393699,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704995537
    },
    {
        "content": "<p>I would guess that LeanCopilot works fine with old std, and the problem is that <code>lake update</code> is too aggressive</p>",
        "id": 412393787,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704995571
    },
    {
        "content": "<p>so what do I do? I'm a lake noob</p>",
        "id": 412394507,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704995875
    },
    {
        "content": "<p>Revert the change to that line</p>",
        "id": 412394572,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704995888
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 412394589,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704995898
    },
    {
        "content": "<p>Either manually, or with the <code>checkout</code> command I gave you above</p>",
        "id": 412394590,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704995898
    },
    {
        "content": "<blockquote>\n<p>$image</p>\n</blockquote>\n<p>I'm afraid that strategy won't work here</p>",
        "id": 412394650,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704995920
    },
    {
        "content": "<p>yeah that's the problem :-/</p>",
        "id": 412394695,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704995938
    },
    {
        "content": "<p>If I revert the change to that file then I'll also remove this part:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">+</span>   <span class=\"s2\">\"rev\"</span><span class=\"o\">:</span> <span class=\"s2\">\"5e5b19486d8b850aa4f3f3169e95de560f39b2f8\"</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"name\"</span><span class=\"o\">:</span> <span class=\"s2\">\"LeanCopilot\"</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"manifestFile\"</span><span class=\"o\">:</span> <span class=\"s2\">\"lake-manifest.json\"</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"inputRev\"</span><span class=\"o\">:</span> <span class=\"s2\">\"v1.0.1\"</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"inherited\"</span><span class=\"o\">:</span> <span class=\"n\">false</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"configFile\"</span><span class=\"o\">:</span> <span class=\"s2\">\"lakefile.lean\"</span><span class=\"o\">},</span>\n<span class=\"bp\">+</span>  <span class=\"o\">{</span><span class=\"s2\">\"url\"</span><span class=\"o\">:</span> <span class=\"s2\">\"https://github.com/leanprover-community/quote4\"</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"type\"</span><span class=\"o\">:</span> <span class=\"s2\">\"git\"</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"subDir\"</span><span class=\"o\">:</span> <span class=\"n\">null</span><span class=\"o\">,</span>\n<span class=\"bp\">+</span>   <span class=\"s2\">\"rev\"</span><span class=\"o\">:</span> <span class=\"s2\">\"1c88406514a636d241903e2e288d21dc6d861e01\"</span><span class=\"o\">,</span>\n</code></pre></div>",
        "id": 412394976,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704996026
    },
    {
        "content": "<p>I meant remove just the one line</p>",
        "id": 412395009,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996037
    },
    {
        "content": "<p><code>git checkout -p</code> asks you piece by piece which ones you want to revert</p>",
        "id": 412395044,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996054
    },
    {
        "content": "<p>Which is why I suggested it :)</p>",
        "id": 412395072,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996061
    },
    {
        "content": "<p>yeah, that was when I gave up</p>",
        "id": 412395085,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704996065
    },
    {
        "content": "<p>I had to choose between <code>[y,n,q,a,d,s,e,?]</code> with no clues</p>",
        "id": 412395122,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704996085
    },
    {
        "content": "<p><code>?</code> is \"give clues\", <code>y</code> is \"yes revert\", <code>n</code> is \"no leave alone\"</p>",
        "id": 412395175,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996109
    },
    {
        "content": "<p>I don't like the look of this though:</p>\n<div class=\"codehilite\" data-code-language=\"Diff\"><pre><span></span><code>buzzard@buster:~/lean-projects/formalising-mathematics-2024$ git checkout -p HEAD lake-manifest.json\n<span class=\"gh\">diff --git a/lake-manifest.json b/lake-manifest.json</span>\n<span class=\"gh\">index 4448554..368aca5 100644</span>\n<span class=\"gd\">--- a/lake-manifest.json</span>\n<span class=\"gi\">+++ b/lake-manifest.json</span>\n<span class=\"gu\">@@ -4,26 +4,35 @@</span>\n<span class=\"w\"> </span> [{\"url\": \"https://github.com/leanprover/std4\",\n<span class=\"w\"> </span>   \"type\": \"git\",\n<span class=\"w\"> </span>   \"subDir\": null,\n<span class=\"gd\">-   \"rev\": \"d8610e1bcb91c013c3d868821c0ef28bf693be07\",</span>\n<span class=\"gi\">+   \"rev\": \"ee49cf8fada1bf5a15592c399a925c401848227f\",</span>\n<span class=\"w\"> </span>   \"name\": \"std\",\n<span class=\"w\"> </span>   \"manifestFile\": \"lake-manifest.json\",\n<span class=\"w\"> </span>   \"inputRev\": \"main\",\n<span class=\"w\"> </span>   \"inherited\": true,\n<span class=\"w\"> </span>   \"configFile\": \"lakefile.lean\"},\n<span class=\"gd\">-  {\"url\": \"https://github.com/leanprover-community/quote4\",</span>\n<span class=\"gi\">+  {\"url\": \"https://github.com/JLimperg/aesop\",</span>\n<span class=\"w\"> </span>   \"type\": \"git\",\n<span class=\"w\"> </span>   \"subDir\": null,\n<span class=\"gd\">-   \"rev\": \"1c88406514a636d241903e2e288d21dc6d861e01\",</span>\n<span class=\"gd\">-   \"name\": \"Qq\",</span>\n<span class=\"gi\">+   \"rev\": \"69404390bdc1de946bf0a2e51b1a69f308e56d7a\",</span>\n<span class=\"gi\">+   \"name\": \"aesop\",</span>\n<span class=\"w\"> </span>   \"manifestFile\": \"lake-manifest.json\",\n<span class=\"w\"> </span>   \"inputRev\": \"master\",\n<span class=\"w\"> </span>   \"inherited\": true,\n<span class=\"w\"> </span>   \"configFile\": \"lakefile.lean\"},\n<span class=\"gd\">-  {\"url\": \"https://github.com/leanprover-community/aesop\",</span>\n<span class=\"gi\">+  {\"url\": \"https://github.com/lean-dojo/LeanCopilot.git\",</span>\n<span class=\"w\"> </span>   \"type\": \"git\",\n<span class=\"w\"> </span>   \"subDir\": null,\n<span class=\"gd\">-   \"rev\": \"69404390bdc1de946bf0a2e51b1a69f308e56d7a\",</span>\n<span class=\"gd\">-   \"name\": \"aesop\",</span>\n<span class=\"gi\">+   \"rev\": \"5e5b19486d8b850aa4f3f3169e95de560f39b2f8\",</span>\n<span class=\"gi\">+   \"name\": \"LeanCopilot\",</span>\n<span class=\"gi\">+   \"manifestFile\": \"lake-manifest.json\",</span>\n<span class=\"gi\">+   \"inputRev\": \"v1.0.1\",</span>\n<span class=\"gi\">+   \"inherited\": false,</span>\n<span class=\"gi\">+   \"configFile\": \"lakefile.lean\"},</span>\n<span class=\"gi\">+  {\"url\": \"https://github.com/leanprover-community/quote4\",</span>\n<span class=\"gi\">+   \"type\": \"git\",</span>\n<span class=\"gi\">+   \"subDir\": null,</span>\n<span class=\"gi\">+   \"rev\": \"1c88406514a636d241903e2e288d21dc6d861e01\",</span>\n<span class=\"gi\">+   \"name\": \"Qq\",</span>\n<span class=\"w\"> </span>   \"manifestFile\": \"lake-manifest.json\",\n<span class=\"w\"> </span>   \"inputRev\": \"master\",\n<span class=\"w\"> </span>   \"inherited\": true,\n(1/1) Discard this hunk from index and worktree [y,n,q,a,d,s,e,?]?\n</code></pre></div>",
        "id": 412395233,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704996124
    },
    {
        "content": "<p>Ouch</p>",
        "id": 412395269,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996133
    },
    {
        "content": "<p>Which parts of these do I want to manually revert? Is it \"everything other than LeanCopilot\"?</p>",
        "id": 412395338,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704996189
    },
    {
        "content": "<p>This happened because the name of aesop changed between LeanCopilot and your version of mathlib (leanCopilot is <em>too</em> out of date)</p>",
        "id": 412395364,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996194
    },
    {
        "content": "<p>this is a dead end, a piecewise revert through git is going to fail here</p>",
        "id": 412395385,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996205
    },
    {
        "content": "<p>OK thanks for saving me from screwing everything up royally.</p>",
        "id": 412395416,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704996222
    },
    {
        "content": "<p>I think the thing to do is copy the <code>LeanCopilot</code> section from the file you currently have, then completely revert it</p>",
        "id": 412395510,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996248
    },
    {
        "content": "<p>Then paste in just that new section</p>",
        "id": 412395528,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996255
    },
    {
        "content": "<p>Maybe <span class=\"user-mention\" data-user-id=\"315577\">@Mac Malone</span>  can advise on a better approach here</p>",
        "id": 412395811,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996368
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> <br>\nThere are AST digesting language models that take an AST as input instead of taking a flat string.<br>\nThey can't be pre-trained on loads of pre-existing human language like Google's byt5 was.<br>\nThere are also just general graph capable transformer variants used quite successfully for e.g. molecules in chemistry.<br>\nThe problem is that when you don't use the string variant, you have to somehow emit the structured variant for tactics that take fresh expressions.</p>\n<p>If you or <span class=\"user-mention\" data-user-id=\"470149\">@Joachim Breitner</span>  want to investigate, DM me, I'm working towards this (for Lean4).</p>",
        "id": 412395890,
        "sender_full_name": "namibj",
        "timestamp": 1704996403
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"678785\">namibj</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412395890\">said</a>:</p>\n<blockquote>\n<p>There are AST digesting language models that take an AST as input instead of taking a flat string.</p>\n</blockquote>\n<p>Can you point us to some examples?</p>",
        "id": 412396619,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1704996725
    },
    {
        "content": "<blockquote>\n<p>now lake exe cache get followed by lake build is building Std. Is this expected?</p>\n</blockquote>\n<p>It's fine as long as it's not building mathlib? Building Std only shouldn't take long.</p>",
        "id": 412396760,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1704996798
    },
    {
        "content": "<p>Mathlib will rebuild if std was rebuilt</p>",
        "id": 412396794,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704996813
    },
    {
        "content": "<p>OK, is there anything I can do on LeanCopilot's side to solve this problem? </p>\n<p>E.g., updating the aesop dependency?</p>",
        "id": 412397038,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1704996932
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412395510\">said</a>:</p>\n<blockquote>\n<p>I think the thing to do is copy the <code>LeanCopilot</code> section from the file you currently have, then completely revert it</p>\n<p>Then paste in just that new section</p>\n</blockquote>\n<p>Thanks a lot Eric -- this seems to have worked; I have Lean Copilot running in my repo!</p>",
        "id": 412397351,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704997073
    },
    {
        "content": "<p>What happens if you do <code>lake update LeanCopilot</code> followed by <code>lake update mathlib</code>? Does it keep LeanCopilot in the manifest but uses mathlib's std version?</p>",
        "id": 412397447,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1704997103
    },
    {
        "content": "<p>Updating aesop to the leanprover-community version would maybe make this less painful</p>",
        "id": 412397452,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704997105
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"325367\">Mauricio Collares</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412397447\">said</a>:</p>\n<blockquote>\n<p>What happens if you do <code>lake update LeanCopilot</code> followed by <code>lake update mathlib</code>? Does it keep LeanCopilot in the manifest but uses mathlib's std version?</p>\n</blockquote>\n<p>Yes, but this also bumps mathlib!</p>",
        "id": 412397472,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704997115
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412396619\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"678785\">namibj</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412395890\">said</a>:</p>\n<blockquote>\n<p>There are AST digesting language models that take an AST as input instead of taking a flat string.</p>\n</blockquote>\n<p>Can you point us to some examples?</p>\n</blockquote>\n<p><a href=\"https://arxiv.org/abs/1911.01545\">https://arxiv.org/abs/1911.01545</a><br>\nThey gave up/didn't publish their tries to Python AST; it's just mentioned in one of the versions in the LaTeX source code you can download as other format (a .tar with browser-handled .gz around; you'll rename to .tar and can then use it).<br>\nThey \"only\" tackle some fairly simple math terms, basically phone calculator tier in function availability, but the idea scales somewhat further.</p>\n<p>They use it to classify term pairs as equal/unequal and also use it to do blank filling up to iirc depth 2. iirc the latter is a fairly brute-force decoding approach used; more modern approaches would probably use masked/blanked diffusion model technology to enable generating expressions compliant with some demand/requirements.</p>",
        "id": 412397624,
        "sender_full_name": "namibj",
        "timestamp": 1704997185
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412394589\">said</a>:</p>\n<blockquote>\n<p><a href=\"/user_uploads/3121/I9TUKSEsecyqts9sY_n0v5eX/git_xkcd_edited.png\">git_xkcd_edited.png</a></p>\n</blockquote>\n<p>(I got yelled at for posting a meme to zulip... I guess Kevin is allowed <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> )</p>",
        "id": 412397957,
        "sender_full_name": "Alex Kontorovich",
        "timestamp": 1704997338
    },
    {
        "content": "<blockquote>\n<p>Updating aesop to the leanprover-community version would maybe make this less painful</p>\n</blockquote>\n<p>Doing it now. It will take 15 minutes or so since I have to rebuild the cloud release.</p>",
        "id": 412397967,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1704997342
    },
    {
        "content": "<p>Updating to a similar quote4 might help too (assuming you have that as a dependency)</p>",
        "id": 412398062,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704997398
    },
    {
        "content": "<p>But I think realistically you either need a new lake feature, or instructions to manually edit the lake manifest</p>",
        "id": 412398113,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704997429
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412397472\">said</a>:</p>\n<blockquote>\n<p>Yes, but this also bumps mathlib!</p>\n</blockquote>\n<p>Hmm, and what if you edit the lakefile (not the manifest) to pin a particular rev before running <code>lake update mathlib</code>? Does it try to update again when changing the lakefile back to master?</p>",
        "id": 412398191,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1704997451
    },
    {
        "content": "<p>Yes, that should work</p>",
        "id": 412398231,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704997469
    },
    {
        "content": "<p>meme: Sorry :-( I'm not allowed at all (it's now deleted). I was frustrated. The infrastructure around Lean 4 is infinitely more complex than the analogous Lean 3 set-up. I guess this is a sign of progress though.</p>\n<p>On the plus side, I'm at Xena right now and an undergrad just asked me how to prove this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">lemma</span> <span class=\"n\">foo</span> <span class=\"o\">(</span><span class=\"n\">X</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">A</span> <span class=\"o\">:</span> <span class=\"n\">Set</span> <span class=\"n\">X</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"o\">(</span><span class=\"n\">A</span> <span class=\"bp\">=</span> <span class=\"bp\">∅</span><span class=\"o\">))</span> <span class=\"o\">:</span> <span class=\"bp\">∃</span> <span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">X</span><span class=\"o\">,</span> <span class=\"n\">x</span> <span class=\"bp\">∈</span> <span class=\"n\">A</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n</code></pre></div>\n<p>and <code>search_proof</code> found a proof!</p>",
        "id": 412398606,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1704997650
    },
    {
        "content": "<p>Updated LeanCopilot's dependencies in <a href=\"https://github.com/lean-dojo/LeanCopilot/releases/tag/v1.0.2\"><code>v1.0.2</code></a>. You would need to update your lakefile.lean if you want to use this version. </p>\n<p>I have to run to the airport for a ski trip to Colorado....will be back next Monday.</p>",
        "id": 412400170,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1704998302
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 413069501,
        "sender_full_name": "Jason Rute",
        "timestamp": 1705373575
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412396619\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"678785\">namibj</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412395890\">said</a>:</p>\n<blockquote>\n<p>There are AST digesting language models that take an AST as input instead of taking a flat string.</p>\n</blockquote>\n<p>Can you point us to some examples?</p>\n</blockquote>\n<p>It is not a language model, but our Graph2Tac (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Announcing.20Graph2Tac.2C.20a.20prover.20based.20on.20Tactician.27s.20new.20API\">#Machine Learning for Theorem Proving &gt; Announcing Graph2Tac, a prover based on Tactician's new API</a>) model takes as input a graph representing the Coq term of the proof state, as well as the Coq terms of any prerequisite definitions (and for argument selection, the Coq terms of any possible tactic arguments in the global context).</p>",
        "id": 413072390,
        "sender_full_name": "Jason Rute",
        "timestamp": 1705375330
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> <a href=\"#narrow/stream/419231-Lean-Together-2024/topic/Towards.20LLMs.20as.20Copilots.20-.20Kaiyu.20Yang/near/412392354\">said</a>:</p>\n<blockquote>\n<p>There are attempts using more machine-oriented representation of states. E.g., [ASTactic] (<a href=\"https://arxiv.org/abs/1905.09381\">https://arxiv.org/abs/1905.09381</a>) and its follow-up works use the ASTs of terms in the form of S-expressions. <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a> uses GNNs to encode the graph of terms. We don't really have enough empirical evidence to know how these non-LLM methods compare to LLM-based methods such as ours, due to difficulties in a fair comparison across different proof assistants.</p>\n</blockquote>\n<p>Thanks for mentioning Graph2Tac!  While I agree it is very hard to compare across systems and approaches, note we do compare Graph2Tac to a transformer-based approach similar to GPT-f, and Graph2Tac does much better.   (And for very short time periods like up to a minute, a simple k-NN model seems to be the best model.)  See Figures 5, 6, 7, 12, 16, and 17 as well as the caveats in the <em>Threats to validity</em> section in the <a href=\"https://arxiv.org/pdf/2401.02949v2.pdf\">current version</a>. This could be for a number of reasons, and I'm happy to discuss it on <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Announcing.20Graph2Tac.2C.20a.20prover.20based.20on.20Tactician.27s.20new.20API\">#Machine Learning for Theorem Proving &gt; Announcing Graph2Tac, a prover based on Tactician's new API</a>.   But, overall, this suggests that more comparison is needed, and as a community, we should be careful not to assume that LLMs solutions, or even neural solutions, are SoTA in this area (especially since, like you said, there are so few comparisons so far).</p>",
        "id": 413072704,
        "sender_full_name": "Jason Rute",
        "timestamp": 1705375541
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> , congrats on the great work! I really like the comparisons in Graph2Tac between Transformers and simpler models such as KNN. I'm wondering why you chose to train the Transformer model from scratch on Coq data, instead of fine-tuning an existing language model such as ByT5 or Mistral 7B. The latter experiment seems more interesting to me, as LLMs are less about Transformers than about pertaining the model on Internet-scale data. E.g., RWKV or Mamba are probably more like LLMs compared to Transformers without pretraining.</p>",
        "id": 416056616,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1705505786
    },
    {
        "content": "<p>(apologies for leeching onto this thread, but I figured the people interested in this message would be in it) I did some quick experiments with Claude 3 Opus (<a href=\"https://www.anthropic.com/claude\">https://www.anthropic.com/claude</a>) over the last couple of days and it does do quite an impressive job on reasoning tasks as they claim; for instance it was able to repro <a href=\"https://github.com/eyereasoner/eye/blob/52e8fe064a16e3108d3afa9a54d9ac7d478544d2/reasoning/complex/complex.n3#L19\">this proof</a> with a tiny bit of prompt help such as sample proofs to learn the proof structure (not a lean proof sorry, it's an N3 proof from the domain I primarily work in).</p>\n<p>With the way things are going it seems to me that there could be a valuable student project for someone to create something similar to <a href=\"https://www.cognition-labs.com/introducing-devin\">Devin</a>  for (1) generating proofs from scratch and (2) converting papers to Lean4 proofs. I'd imagine this would use a combination of talking to Claude/GPT, querying moogle, using existing tooling in LeanCopilot and then following the debug cycle similar to that seen in the sample videos.</p>",
        "id": 426939233,
        "sender_full_name": "Jesse Wright",
        "timestamp": 1710632172
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"680656\">@Jesse Wright</span> you might also be interested in the <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> stream.  That would also be a good place to discuss this.</p>",
        "id": 426987882,
        "sender_full_name": "Jason Rute",
        "timestamp": 1710645890
    }
]