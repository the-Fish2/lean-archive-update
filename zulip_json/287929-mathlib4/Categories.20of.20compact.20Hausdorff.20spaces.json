[
    {
        "content": "<p>There are now four different important subcategories of compact Hausdorff spaces in Mathlib (<code>CompHaus</code>, <code>Profinite</code>, <code>Stonean</code>, and <code>LightProfinite</code>). They are all used for similar purposes (being the defining site for variants of condensed sets). This leads to quite a lot of code repetition and I'm thinking about a refactor where their definitions are unified by defining a structure <code>CompHausLike</code> as follows</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.Topology.Category.TopCat.Basic</span>\n\n<span class=\"kd\">universe</span> <span class=\"n\">u</span>\n\n<span class=\"kn\">open</span> <span class=\"n\">CategoryTheory</span>\n\n<span class=\"kd\">variable</span> <span class=\"o\">(</span><span class=\"n\">P</span> <span class=\"o\">:</span> <span class=\"n\">TopCat.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"bp\">→</span> <span class=\"kt\">Prop</span><span class=\"o\">)</span>\n\n<span class=\"sd\">/-- The type of Compact Hausdorff topological spaces satisfying an additional property `P`. -/</span>\n<span class=\"kd\">structure</span> <span class=\"n\">CompHausLike</span> <span class=\"n\">where</span>\n  <span class=\"sd\">/-- The underlying topological space of an object of `CompHausLike P`. -/</span>\n  <span class=\"n\">toTop</span> <span class=\"o\">:</span> <span class=\"n\">TopCat</span>\n  <span class=\"sd\">/-- The underlying topological space is compact. -/</span>\n  <span class=\"o\">[</span><span class=\"n\">is_compact</span> <span class=\"o\">:</span> <span class=\"n\">CompactSpace</span> <span class=\"n\">toTop</span><span class=\"o\">]</span>\n  <span class=\"sd\">/-- The underlying topological space is T2. -/</span>\n  <span class=\"o\">[</span><span class=\"n\">is_hausdorff</span> <span class=\"o\">:</span> <span class=\"n\">T2Space</span> <span class=\"n\">toTop</span><span class=\"o\">]</span>\n  <span class=\"sd\">/-- The underlying topological space satisfies P. -/</span>\n  <span class=\"n\">prop</span> <span class=\"o\">:</span> <span class=\"n\">P</span> <span class=\"n\">toTop</span>\n</code></pre></div>\n<p>The current definitions of <code>Stonean</code> and <code>Profinite</code> are essentially this. For <code>LightProfinite</code>, it would be a slightly bigger refactor, but I think we have enough to prove the relevant equivalence of categories. </p>\n<p>The advantage is of  course to be able to prove things for all four categories at once. </p>\n<p>Is this a sensible design decision?</p>",
        "id": 438819487,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715784020
    },
    {
        "content": "<p>I experiment with copying some stuff from <code>CompHaus/Basic</code>  using this approach in <a href=\"https://github.com/leanprover-community/mathlib4/pull/12930\">#12930</a></p>",
        "id": 438819920,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715784128
    },
    {
        "content": "<p>Is it possible to set up the API for categories with a distinguished fully faithful functor to CompHaus? That would be math equivalent to what you propose. But might leave a bit more flexibility in the definitions...</p>",
        "id": 438852847,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1715793932
    },
    {
        "content": "<p>But maybe using the fully faithful functor will be annoying?</p>",
        "id": 438852905,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1715793946
    },
    {
        "content": "<p>The issue with the general fully faithful functor approach is that the objects are too abstract. I want my objects to be topological spaces and my morphisms to be continuous maps. </p>\n<p>Another option would be to use the <code>FullSubcategory</code> API, but that approach would still involve developing some specialised API for full subcategories of <code>TopCat</code> or <code>CompHaus</code>.</p>\n<p>The application I have in mind is to generalise most of what is done in the file <code>Condensed/Discrete/LocallyConstant</code> in <a href=\"https://github.com/leanprover-community/mathlib4/pull/12185\">#12185</a> to <code>CompHausLike P</code> where <code>P</code> is stable under forming finite coproducts (which we have a very explicit construction for in these topological categories). Then deduce the result about discrete condensed sets <em>and</em> light condensed sets at once.</p>",
        "id": 438876676,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715803427
    },
    {
        "content": "<p>More generally, we could get rid of all the repetition in the files <code>CompHaus/Limits</code>, <code>Profinite/Limits</code> etc. and make general constructions for when <code>P</code> is stable under the formation of these limits.</p>",
        "id": 438877180,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715803619
    },
    {
        "content": "<p>I've started the refactor at <a href=\"https://github.com/leanprover-community/mathlib4/pull/12930\">#12930</a> and it breaks surprisingly little for <code>CompHaus</code>, <code>Profinite</code> and <code>Stonean</code>. I'll continue and see how it goes with the limits and <code>LightProfinite</code>, and report back here</p>",
        "id": 438877480,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715803753
    },
    {
        "content": "<p>Could you mimic how concrete categories are set up?</p>",
        "id": 438965112,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1715847426
    },
    {
        "content": "<p>These <code>CompHausLike</code> are meant to be full subcatgeories of <code>CompHaus</code> and not just abstract categories with a forgetful functor to <code>CompHaus</code>. As Johan said, it's mathematically equivalent to set up the API for categories with a distinguished fully faithful functor to <code>CompHaus</code>, but I explained above why I don't want that. </p>\n<p>This approach is also closer to how I think about these categories. For example: why does <code>Profinite</code> have pullbacks? Well, it's because taking the pullback in <code>CompHaus</code>, or <code>TopCat</code>, or whatever, (i.e. forming the subset of the product of those pairs whose coordinates are mapped to the same thing) preserves the property of being totally disconnected. Now we can just do this once for a general <code>CompHausLike P</code> for which <code>P</code> is preserved by forming pullbacks, and not have the whole API for <code>CompHaus.pullback</code>, <code>Profinite.pullback</code>,  <code>LightProfinite.pullback</code>, etc.</p>",
        "id": 438968112,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715848580
    },
    {
        "content": "<p>I'm not sure hat I agree. If you have some predicate <code>P</code> on a the objects of <code>C</code>, you can easily obtain the fully faithful functor from the associated full subcategory. And in order to show that this functor creates limits of a certain shape it quite quickly boils down to showing that <code>P</code> preserves such limits. So I'm not convinced using the approach above would simplify things in any meaningful way. Also, I can imagine having categories which are <code>CompHausLike</code> which are not given by a predicate. For example, <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Compactum#doc\">docs#Compactum</a> or <code>Pro(FinType)</code>.</p>",
        "id": 439004465,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1715861603
    },
    {
        "content": "<p>I don't want to define <code>CompHausLike</code> as a property of categories. I want to define the categories <code>CompHaus</code>, <code>Profinite</code>, <code>Stonean</code> etc. as <code>CompHausLike P</code> for the relevant predicate <code>P</code></p>",
        "id": 439005150,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715861764
    },
    {
        "content": "<p>But why can't those just be full subcategories?</p>",
        "id": 439005279,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1715861795
    },
    {
        "content": "<p>The examples you mention should then have equivalences to <code>CompHaus</code> and <code>Profinite</code></p>",
        "id": 439005321,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715861806
    },
    {
        "content": "<p>I have just found the <code>FullSubcategory</code> API a bit awkward to work with. For example, we don't define <code>CompHaus</code> as a <code>FullSubcategory</code> of <code>TopCat</code> now. We define a structure <code>CompHaus</code> and give it the induced category instance. <code>Profinite</code> and <code>Stonean</code> are defined in a similar way. My point is that these categories share many properties but it's hard to argue about them all at once.</p>",
        "id": 439006547,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715862081
    },
    {
        "content": "<p>Would you rather suggest defining them all as <code>FullSubcategory</code>s of <code>TopCat</code>, and prove theorems about such full subcategories?</p>",
        "id": 439006889,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715862142
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"519559\">Dagur Asgeirsson</span> <a href=\"#narrow/stream/287929-mathlib4/topic/Categories.20of.20compact.20Hausdorff.20spaces/near/439006547\">said</a>:</p>\n<blockquote>\n<p>My point is that these categories share many properties but it's hard to argue about them all at once.</p>\n</blockquote>\n<p>That's a perfectly fair point and I agree. </p>\n<p><span class=\"user-mention silent\" data-user-id=\"519559\">Dagur Asgeirsson</span> <a href=\"#narrow/stream/287929-mathlib4/topic/Categories.20of.20compact.20Hausdorff.20spaces/near/439006889\">said</a>:</p>\n<blockquote>\n<p>Would you rather suggest defining them all as <code>FullSubcategory</code>s of <code>TopCat</code>, and prove theorems about such full subcategories?</p>\n</blockquote>\n<p>To be honest, I don't know what I want to suggest yet. The key points I think we should address are as follows:</p>\n<ul>\n<li>First, as I said above, I agree that we need to have some principled way to reason about all such categories.</li>\n<li>Second, I also think that we might want to abstract away <code>CompHaus</code> itself! By this I mean making some abstraction that either captures <code>CompHaus</code> up to equivalence, or even better, captures only the essential ingredients for condensed math.</li>\n</ul>",
        "id": 439010894,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1715863218
    },
    {
        "content": "<p>The second point is interesting, but I'm almost going in the opposite direction here. At least in <a href=\"https://github.com/leanprover-community/mathlib4/pull/12185\">#12185</a> (which is what led me to think about this), where I prove that the <code>S</code>-valued points of a discrete condensed set <code>X</code> are the locally constant maps <code>S \\to X</code>, I heavily use the definitional properties of finite coproducts in <code>CompHaus</code>. I want to change every occurence of <code>CompHaus</code> in that file to <code>CompHausLike P</code> where <code>P</code> is preserved by taking finite coproducts, and deduce the same thing for condensed and light condensed sets at once.</p>",
        "id": 439012943,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715863867
    },
    {
        "content": "<p>What do you have in mind when you say the \"essential ingredients\" for condensed math? We also need to keep in mind light condensed sets</p>",
        "id": 439013040,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1715863903
    },
    {
        "content": "<p>yeah the light stuff complicates things, but I'm sure there is some natural abstraction from general stone duality. Maybe we should invite <span class=\"user-mention\" data-user-id=\"411579\">@Sam van G</span> to the discussion?</p>",
        "id": 439015886,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1715864692
    },
    {
        "content": "<p>Thanks for the invitation and sorry for the delay :) I’m not completely sure what the question is so just some loose remarks. As you know, (light) profinite sets are dually equivalent to (countable) Boolean algebras, but I would expect to encounter the same problem on the other side of the duality. Stone duality for non-zero-dimensional spaces is an interesting field with active research. Not sure if it will be immediately useful here. <br>\nFrom just reading the discussion above, it sounds like the FullSubcategory API is what mostly needs work? I haven’t had to work with it myself but I have generally found categories in Mathlib more difficult to work with than, say, algebra or topology, so I understand why some are hesitant.</p>",
        "id": 439330611,
        "sender_full_name": "Sam van G",
        "timestamp": 1716013387
    },
    {
        "content": "<p>I guess one concrete question I'm thinking of is whether <code>Profinite</code> can be distinguished in purely categorical terms within <code>CompHaus</code>? I know how to do it if we have not just the category <code>CompHaus</code> but also the forgetful functor <code>CompHaus -&gt; Type</code>. Any ideas?</p>",
        "id": 439355996,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1716039665
    },
    {
        "content": "<p>You can distinguish the terminal object, hence finite sets. So you can look at all finite quotients of a space, and take the limit of that diagram. And if the map to that limit is an iso, then it must have been a profinite space.</p>",
        "id": 439357022,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1716040577
    },
    {
        "content": "<p>Is the compatibility with the coherent topologies clear from this description?</p>",
        "id": 439357871,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1716041358
    },
    {
        "content": "<p>One observation is that a finite quotient is \"the same thing\" as a (finitely) extensive cover.</p>",
        "id": 439359252,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1716042603
    },
    {
        "content": "<p>What is the problem with the topologies in Johan's argument?</p>",
        "id": 439363587,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1716046451
    },
    {
        "content": "<p>Within CompHaus, the objects that are in Profinite are exactly those that are filtered limits of diagrams of finite objects (where you can choose any definition of finite that you like, for example finite coproducts of terminal objects). This is equivalent to what Johan said except that his description builds the space in a specific way, by looking at the diagram of all of its finite quotients. In my experience, when proving things -on paper- about profinite spaces, depending on the context, in some situations you want to use that specific diagram, in other situations you want to say \"there is some filtered diagram that can build it and I don't care what it looks like\".</p>",
        "id": 439368018,
        "sender_full_name": "Sam van G",
        "timestamp": 1716050853
    },
    {
        "content": "<p>It's not that there's a problem with Johan's argument, but with this point of view it's not clear to me how to make some of the arguments in condensed mathematics work. For example if you have some comphaus <code>X</code>, you get a natural map from <code>X</code> to the limit of all its finite quotients, which would be profinite. But when you go to prove that sheaves on CompHaus agree with sheaves on Profinite you need to resolve <code>X</code> by a profinite, so you need to cover <code>X</code> by some profinite <code>Y</code>. If you take the point of view that CompHaus are algebras for the codensity monad of the inclusion of <code>Fintype</code> into <code>Type</code>, then you get this \"for free\" by looking at the adjunction associated to this monad (and the counit would be such a cover).</p>",
        "id": 439370221,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1716053154
    },
    {
        "content": "<p>Related to Sam's comment: In <a href=\"https://github.com/dagurtomas/LeanCondensed/blob/master/LeanCondensed/Discrete/Extend.lean\">https://github.com/dagurtomas/LeanCondensed/blob/master/LeanCondensed/Discrete/Extend.lean</a> I prove that every cofiltered diagram of finite sets with surjective transition maps which is a limit cone in <code>Profinite</code> is equivalent to a diagram indexed by structured arrows from its cone point to the functor <code>FintypeCat.toProfinite</code> (equivalent in the sense that they are related by an initial functor, i.e. have the same limit)</p>",
        "id": 439462959,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1716148833
    },
    {
        "content": "<p>There was something similar, <code>Profinite.extend</code>, in LTE, but there it was not proved to be equivalent to the right Kan extension if I remember correctly</p>",
        "id": 439463004,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1716148873
    },
    {
        "content": "<p>I thought some people here might also be interested in <a href=\"#narrow/stream/217875-Is-there-code-for-X.3F/topic/Stone.20duality/near/440177188\">this thread</a>: We now have a (very long and not yet Mathlib-ready, but) sorry-free proof of Stone duality for <code>Profinite</code>.</p>",
        "id": 440177744,
        "sender_full_name": "Sam van G",
        "timestamp": 1716409948
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib4/pull/13319\">#13319</a> refactors the definition of <code>LightProfinite</code> to mirror the definition of <code>Profinite</code>. It also provides an equivalence of categories with the old definition, proves that <code>LightProfinite</code> has countable limits, and that the functor to <code>Profinite</code> creates countable limits. </p>\n<p>I think this is a good change, and we don't \"lose\" anything because we have the equivalence of categories with the old definition. I have plans for a followup PR to provide more API to interact with light profinite sets as sequential limits of finite sets.</p>\n<p>I would then like to go further and unify all the definitions of <code>CompHaus</code>, <code>Profinite</code>, <code>LightProfinite</code> and <code>Stonean</code> as some form of my suggested <code>CompHausLike</code>, but that's not quite ready yet.</p>",
        "id": 441098061,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1716922996
    },
    {
        "content": "<p>I've also checked that this refactor doesn't break anything related to light condensed stuff in <a href=\"https://github.com/leanprover-community/mathlib4/pull/9526\">#9526</a></p>",
        "id": 441098688,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1716923272
    },
    {
        "content": "<p>I think I've found some pretty good API for a unified definition of these categories, see <a href=\"https://github.com/leanprover-community/mathlib4/pull/12930\">#12930</a>. </p>\n<p>Some evidence for the fact that this API is good is the big negative diff, and the fact that it can be used to prove a characterisation of discrete condensed sets and light condensed sets at the same time (<a href=\"https://github.com/leanprover-community/mathlib4/pull/13893\">#13893</a>). </p>\n<p>Unfortunately the refactor touches 23 files and might be a bit difficult to review. Would it be better to add the new definition first without refactoring the old ones? Or any other ideas to make this easier to review?</p>",
        "id": 445171524,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718640881
    },
    {
        "content": "<p>Here are a few tips I have when doing a large refactor:</p>\n<ol>\n<li>Don't ever move AND add/delete lemmas in the same PR.</li>\n<li>If you can afford to leave the old API around while adding the new API, do. You can always clean it up a later PR.</li>\n<li>If you can afford to redefine the old API in terms of the new one (replacing <code>lemma old_foo := complicated_stuff</code> by <code>lemma old_foo := new_foo</code>, do. You can always clean it up a later PR.</li>\n</ol>",
        "id": 445216392,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1718655223
    },
    {
        "content": "<p>Thanks that's very helpful! </p>\n<p>I'm not sure I understand point 3. Do you mean that I should, when the new API is in place, and I've redefined the old structures in terms of the new API, start by keeping all the old lemmas, reproving them using the new API if necessary, and then in a followup PR remove the ones that are now unnecessary?</p>",
        "id": 445217450,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718655616
    },
    {
        "content": "<p>I will at least start by opening a separate PR which only adds the new stuff</p>",
        "id": 445217513,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718655636
    },
    {
        "content": "<p>For point 3, consider the pair:</p>\n<ul>\n<li><a href=\"https://github.com/leanprover-community/mathlib/pull/14000\">!3#14000</a> adding a bunch of new lemmas in a temporary <code>division_monoid</code> namespace and reproving the old lemmas in terms of them</li>\n<li><a href=\"https://github.com/leanprover-community/mathlib/pull/14042\">!3#14042</a> deleting the old lemmas and removing the namespace from the new lemmas</li>\n</ul>",
        "id": 445218518,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1718655982
    },
    {
        "content": "<p>Ok I see, this seems very reasonable, but your example is a much deeper refactor than what I'm doing. In my case I think it's a bit overkill, since this part of mathlib is not widely used. <br>\nBut I think I'll at least take the approach of introducing the new API gradually, to avoid these massive diffs</p>",
        "id": 445219392,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718656299
    },
    {
        "content": "<p>Ok to start, there is the tower</p>\n<p><a href=\"https://github.com/leanprover-community/mathlib4/pull/13904\">#13904</a> (add <code>CompHausLike/Basic</code>)<br>\n<a href=\"https://github.com/leanprover-community/mathlib4/pull/13905\">#13905</a> (add <code>CompHausLike/Limits</code>)<br>\n<a href=\"https://github.com/leanprover-community/mathlib4/pull/13907\">#13907</a> (add <code>CompHausLike/EffectiveEpi</code>)<br>\n<a href=\"https://github.com/leanprover-community/mathlib4/pull/13908\">#13908</a> (refactor <code>CompHaus/Basic</code> in terms of <code>CompHausLike</code>)<br>\n<a href=\"https://github.com/leanprover-community/mathlib4/pull/13909\">#13909</a> (refactor <code>Profinite/Basic</code> in terms of <code>CompHausLike</code>)<br>\n<a href=\"https://github.com/leanprover-community/mathlib4/pull/13911\">#13911</a> (refactor <code>Stonean/Basic</code> in terms of <code>CompHausLike</code>)<br>\n<a href=\"https://github.com/leanprover-community/mathlib4/pull/13912\">#13912</a> (refactor <code>LightProfinite/Basic</code> in terms of <code>CompHausLike</code>).</p>\n<p>In particular, I didn't touch the old limit API unless to fix errors. It will then be mostly removed and unified in <a href=\"https://github.com/leanprover-community/mathlib4/pull/12930\">#12930</a>.</p>",
        "id": 445232930,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718661706
    },
    {
        "content": "<p>So basically one file gets added/refactored in each PR, and each PR only touches other files if necessary to fix errors</p>",
        "id": 445233049,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718661754
    },
    {
        "content": "<p>So the first three PRs contain the new material, right?</p>",
        "id": 445306531,
        "sender_full_name": "Riccardo Brasca",
        "timestamp": 1718701188
    },
    {
        "content": "<p>I mean, those are not refactoring anything</p>",
        "id": 445306551,
        "sender_full_name": "Riccardo Brasca",
        "timestamp": 1718701194
    },
    {
        "content": "<p>Yes, that’s right</p>",
        "id": 445306674,
        "sender_full_name": "Dagur Asgeirsson",
        "timestamp": 1718701219
    },
    {
        "content": "<p>I am really sorry that I still haven't found time to review these. And it looks like I won't have time in the next few days either.</p>\n<p>Can I bump this on someone elses review queue?</p>",
        "id": 447173375,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1719395951
    }
]