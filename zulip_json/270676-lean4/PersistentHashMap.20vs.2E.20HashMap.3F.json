[
    {
        "content": "<p>I’m wondering what the difference between <code>PersistentHashMap</code> and <code>HashMap</code> is. </p>\n<ol>\n<li>What sort of “persistence” is maintained by the former and not the latter?</li>\n<li>When might I want to use one over the other?</li>\n</ol>\n<p><code>PersistentHashMap</code> is used in some core data structures—e.g. the local context maintains one to associate fvarids with decls—so I imagine they’re the right choice for these applications, and I’d like to understand why. :)</p>",
        "id": 436313553,
        "sender_full_name": "Thomas Murrills",
        "timestamp": 1714495454
    },
    {
        "content": "<p>If you have hash maps <code>a</code> and <code>b := a.insert x y</code> and you have live pointers to <code>a</code> and <code>b</code> at the same time, then <code>b</code> is a full copy of <code>a</code> with one additional element. So modifications of hash maps are only efficient if they are made linearly, i.e. <code>a</code> is not used after <code>b</code> has been constructed (similar to <code>Array</code>).  By contrast, persistent hash maps support reasonably efficient non-linear modifications, but they are less efficient when used linearly.</p>\n<p>Core data structures often use persistent hash maps because these data structures end up in long-lived snapshots used by the server, among other things.</p>",
        "id": 436316554,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1714496475
    },
    {
        "content": "<p>In particular, <code>b</code> tries to be efficient by sharing internal structure with <code>a</code> when they're persistent hash maps — they're like trees. If they're plain <code>HashMap</code>s, insertion copies the whole backing <code>Array</code> (unless there's just one reference and it can be updated in-place)</p>",
        "id": 436316949,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1714496599
    },
    {
        "content": "<p>Ah, okay, knowing it’s essentially similar to the <code>List</code>/<code>Array</code> difference re: linearity makes sense, thanks! :)</p>",
        "id": 436318032,
        "sender_full_name": "Thomas Murrills",
        "timestamp": 1714496917
    },
    {
        "content": "<p>But, interestingly, I notice we have <code>PersistentArray</code> too. I’m guessing this is like a shareable version of <code>Array</code> with more efficient access-by-index than <code>List</code> (to match the typical <code>Array</code> operations)?</p>",
        "id": 436323063,
        "sender_full_name": "Thomas Murrills",
        "timestamp": 1714498555
    },
    {
        "content": "<p>Yes. Its basically a tree  where the tips are individual arrays so you get something that is very close to constant access time and you only have to copy individual parts of the tree when using it in a non linear fashion</p>",
        "id": 436323410,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1714498687
    },
    {
        "content": "<p>Persistent lazy data structures have good amortized time complexity.</p>",
        "id": 436324683,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1714499218
    },
    {
        "content": "<p>I don't know if lean uses lazy data structures much though</p>",
        "id": 436325214,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1714499448
    },
    {
        "content": "<p>Is it useful? EDIT: More specifically, beyond the theoretical trade offs between amortized and worst case complexity, what are the practical considerations?</p>",
        "id": 436325230,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1714499456
    },
    {
        "content": "<p>There is a bit of lazyness in Lean's implementation here and there but it is not as much as we use persistent or linear structures by far</p>",
        "id": 436325712,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1714499654
    }
]