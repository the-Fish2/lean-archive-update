[
    {
        "content": "<p>I had a  silly question I should have asked long ago. Does lean reduce terms inside binders before applying the function? If I were to write a CPS style tail recursive function, would the continuations just pile up as a big thunk or get reduced at each recursive call?</p>",
        "id": 416799516,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705677541
    },
    {
        "content": "<p>Here's  a textbook example as an <a href=\"https://leanprover-community.github.io/mwe.html\">#mwe</a>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.Tactic</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">sum_cont_aux</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cont</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"k\">match</span> <span class=\"n\">xs</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"o\">[]</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">cont</span> <span class=\"mi\">0</span>\n  <span class=\"bp\">|</span> <span class=\"n\">y</span> <span class=\"o\">::</span> <span class=\"n\">ys</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">ys</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">n</span> <span class=\"bp\">↦</span> <span class=\"n\">cont</span> <span class=\"o\">(</span><span class=\"n\">y</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">))</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">sum_and_id</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">xs</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">x</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n<span class=\"kd\">def</span> <span class=\"n\">sum_and_square</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">xs</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">x</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">x</span> <span class=\"bp\">*</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n<span class=\"k\">#reduce</span> <span class=\"n\">sum_and_id</span> <span class=\"o\">[</span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"mi\">2</span><span class=\"o\">,</span><span class=\"mi\">3</span><span class=\"o\">,</span><span class=\"mi\">4</span><span class=\"o\">]</span> <span class=\"c1\">-- 10</span>\n</code></pre></div>",
        "id": 416801708,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705678126
    },
    {
        "content": "<p>In the runtime you just get a big pile of thunks. CPS transformation, roughly speaking, puts on the heap what would normally be on the stack :-)</p>",
        "id": 416833651,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1705686176
    },
    {
        "content": "<p>what's more, I think lean will not do TCO to <code>cont</code> in the generated thunk, meaning that this program will use O(n) stack and run out for large n, not on the way down (this is tail recursive) but on the way back, when you call <code>cont 0</code> on your giant stack of thunks and it calls another thunk which calls another thunk etc</p>",
        "id": 416840803,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1705688497
    },
    {
        "content": "<p>Is there a way to generate these thunks and inspect them within lean?</p>",
        "id": 416842058,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705688885
    },
    {
        "content": "<p>And to get more to the point, measure the evaluation time?</p>",
        "id": 416842357,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705688992
    },
    {
        "content": "<p>Similar to the Linux time command</p>",
        "id": 416842432,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705689008
    },
    {
        "content": "<p>you should be able to use <code>set_option profiler true</code> and/or <code>#time</code> to time things</p>",
        "id": 416842780,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1705689125
    },
    {
        "content": "<p>Do I need additional imports (I always have Mathlib.Tactic)</p>",
        "id": 416843178,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705689249
    },
    {
        "content": "<p>It doesn't work as is</p>",
        "id": 416843190,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705689254
    },
    {
        "content": "<p>Current toolchain : leanprover/lean4:v4.5.0-rc1</p>",
        "id": 416844102,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705689595
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/Term.20reduction.20order/near/416840803\">said</a>:</p>\n<blockquote>\n<p>what's more, I think lean will not do TCO to <code>cont</code> in the generated thunk</p>\n</blockquote>\n<p>wait, really? <span aria-label=\"frowning\" class=\"emoji emoji-1f626\" role=\"img\" title=\"frowning\">:frowning:</span> that feels like a big missed opportunity</p>",
        "id": 416849469,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1705691488
    },
    {
        "content": "<p>For efficient reduction, you might want to use a strictness operator to force <code>y</code> to evaluate. I think this works?</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.Tactic</span>\n\n<span class=\"kd\">set_option</span> <span class=\"n\">autoImplicit</span> <span class=\"n\">true</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">Nat.strict</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">k</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"o\">:=</span>\n  <span class=\"k\">match</span> <span class=\"n\">n</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"mi\">0</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">k</span> <span class=\"mi\">0</span>\n  <span class=\"bp\">|</span> <span class=\"n\">_</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">k</span> <span class=\"n\">n</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">sum_cont_aux</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cont</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"k\">match</span> <span class=\"n\">xs</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"o\">[]</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">cont</span> <span class=\"mi\">0</span>\n  <span class=\"bp\">|</span> <span class=\"n\">y</span> <span class=\"o\">::</span> <span class=\"n\">ys</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">Nat.strict</span> <span class=\"n\">y</span> <span class=\"k\">fun</span> <span class=\"n\">y</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">ys</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">n</span> <span class=\"bp\">↦</span> <span class=\"n\">cont</span> <span class=\"o\">(</span><span class=\"n\">y</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">))</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">sum_and_id</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">xs</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">x</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n<span class=\"kd\">def</span> <span class=\"n\">sum_and_square</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">xs</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">x</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">x</span> <span class=\"bp\">*</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n<span class=\"bp\">#</span><span class=\"n\">whnf</span> <span class=\"n\">sum_and_id</span> <span class=\"o\">[</span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"mi\">2</span><span class=\"o\">,</span><span class=\"mi\">3</span><span class=\"o\">,</span><span class=\"mi\">4</span><span class=\"o\">]</span> <span class=\"c1\">-- 10</span>\n</code></pre></div>\n<p>Also, no need for <code>#reduce</code> if it's just a Nat, unless you want to partially evaluate something with free variables.</p>",
        "id": 416861476,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1705695983
    },
    {
        "content": "<p>There's a chance this would work too:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">Nat.seq</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"o\">:=</span>\n  <span class=\"k\">match</span> <span class=\"n\">n</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"mi\">0</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">b</span>\n  <span class=\"bp\">|</span> <span class=\"n\">_</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">b</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">sum_cont_aux</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cont</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"k\">match</span> <span class=\"n\">xs</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"o\">[]</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">cont</span> <span class=\"mi\">0</span>\n  <span class=\"bp\">|</span> <span class=\"n\">y</span> <span class=\"o\">::</span> <span class=\"n\">ys</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">Nat.seq</span> <span class=\"n\">y</span> <span class=\"bp\">&lt;|</span> <span class=\"n\">sum_cont_aux</span> <span class=\"n\">ys</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">n</span> <span class=\"bp\">↦</span> <span class=\"n\">cont</span> <span class=\"o\">(</span><span class=\"n\">y</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">))</span>\n</code></pre></div>\n<p>but I haven't tested it carefully. It's like the haskell <code>seq</code> operator, and it's relying on the fact that it's adding the reduction of <code>y</code> to the cache. The cost of these solutions by the way are additional stack frames for evaluating <code>Nat.strict</code>/<code>Nat.cont</code>. I think <code>Nat.seq</code> might be better here, if it works.</p>",
        "id": 416861686,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1705696082
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"407274\">@James Gallicchio</span> I think there are plenty of missed opportunities around due to having had no resources put towards them yet. So far, having a correct and simple kernel has been the priority. Making the kernel support TCO in an efficient way would make its implementation less simple, or at least it would take restructuring how it works so that there aren't multiple C++ stack frames in the way of performing TCO.</p>\n<p>I know <a href=\"https://lean-fro.org/about/roadmap/\">one of the missions of the FRO</a> is to improve proof by reflection support. Maybe this is something that will have resources put into it at some point. I don't know this part of the roadmap, so this is just speculation on my part.</p>",
        "id": 416863443,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1705696825
    },
    {
        "content": "<p>Is the reduction order identical in the kernel and the VM. That would be strange because the VM is just executing code and trying to be optimal, whereas the kernel needs to be faithful to the user's definition upto some syntactic level (or maybe Expr)</p>",
        "id": 416863570,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705696892
    },
    {
        "content": "<p>No, it's not identical. When doing whnf code is evaluated lazily, effectively.</p>",
        "id": 416863796,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1705696973
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306601\">Kyle Miller</span> <a href=\"#narrow/stream/270676-lean4/topic/Term.20reduction.20order/near/416863443\">said</a>:</p>\n<blockquote>\n<p>Making the kernel support TCO in an efficient way would make its implementation less simple</p>\n</blockquote>\n<p>I mostly mean the runtime, not the kernel. But yeah, the super-constrained resources nonetheless applies <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span> I'm also guessing (hoping?) the new compiler will make this easier to implement</p>",
        "id": 416864865,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1705697406
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/stream/270676-lean4/topic/Term.20reduction.20order/near/416863570\">said</a>:</p>\n<blockquote>\n<p>Is the reduction order identical in the kernel and the VM. That would be strange because the VM is just executing code and trying to be optimal, whereas the kernel needs to be faithful to the user's definition upto some syntactic level (or maybe Expr)</p>\n</blockquote>\n<p>The VM has no sense of reduction or terms really.</p>",
        "id": 416865218,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1705697557
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"407274\">@James Gallicchio</span> I guess I don't understand what you meant by \"runtime\" since Shreyas was talking about <code>#reduce</code>. Do you mean VM evaluation (<code>#eval</code>) or compiled code evaluation? The compiler for those definitely has TCO.</p>",
        "id": 416865710,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1705697767
    },
    {
        "content": "<p>The VM used in #eval can do TCO. The compiled code is basically at the whim of the C compiler with respect to TCO. This is one of the things that we can e.g. guarantee with the LLVM backend.</p>",
        "id": 416865966,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1705697882
    },
    {
        "content": "<p>You can also see from the <code>set_option trace.compiler true</code> output that it's building a chain of closures:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"o\">[</span><span class=\"n\">compiler.lambda_pure</span><span class=\"o\">]</span> <span class=\"bp\">&gt;&gt;</span> <span class=\"n\">sum_cont_aux._rarg._lambda_1</span> <span class=\"o\">:=</span> <span class=\"k\">fun</span> <span class=\"n\">_x_1</span> <span class=\"n\">_x_2</span> <span class=\"n\">_x_3</span> <span class=\"bp\">↦</span>\n  <span class=\"k\">let</span> <span class=\"n\">_x_4</span> <span class=\"o\">:=</span> <span class=\"n\">Nat.add</span> <span class=\"n\">_x_1</span> <span class=\"n\">_x_3</span><span class=\"bp\">;</span>\n  <span class=\"k\">let</span> <span class=\"n\">_x_5</span> <span class=\"o\">:=</span> <span class=\"n\">_apply</span> <span class=\"n\">_x_2</span> <span class=\"n\">_x_4</span><span class=\"bp\">;</span>\n  <span class=\"n\">_x_5</span>\n<span class=\"o\">[</span><span class=\"n\">compiler.lambda_pure</span><span class=\"o\">]</span> <span class=\"bp\">&gt;&gt;</span> <span class=\"n\">sum_cont_aux._rarg</span> <span class=\"o\">:=</span> <span class=\"k\">fun</span> <span class=\"n\">_x_1</span> <span class=\"n\">_x_2</span> <span class=\"bp\">↦</span>\n  <span class=\"n\">List.casesOn</span>\n    <span class=\"o\">(</span><span class=\"k\">let</span> <span class=\"n\">_x_5</span> <span class=\"o\">:=</span> <span class=\"n\">_proj.0</span> <span class=\"n\">_x_1</span><span class=\"bp\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">_x_6</span> <span class=\"o\">:=</span> <span class=\"n\">_proj.1</span> <span class=\"n\">_x_1</span><span class=\"bp\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">_x_7</span> <span class=\"o\">:=</span> <span class=\"n\">_closure</span> <span class=\"n\">sum_cont_aux._rarg._lambda_1</span> <span class=\"n\">_x_5</span> <span class=\"n\">_x_2</span><span class=\"bp\">;</span>\n    <span class=\"k\">let</span> <span class=\"n\">_x_8</span> <span class=\"o\">:=</span> <span class=\"n\">sum_cont_aux._rarg</span> <span class=\"n\">_x_6</span> <span class=\"n\">_x_7</span><span class=\"bp\">;</span>\n    <span class=\"n\">_x_8</span><span class=\"o\">)</span>\n<span class=\"o\">[</span><span class=\"n\">compiler.lambda_pure</span><span class=\"o\">]</span> <span class=\"bp\">&gt;&gt;</span> <span class=\"n\">sum_cont_aux</span> <span class=\"o\">:=</span> <span class=\"k\">fun</span> <span class=\"n\">_x_1</span> <span class=\"bp\">↦</span>\n  <span class=\"k\">let</span> <span class=\"n\">_x_2</span> <span class=\"o\">:=</span> <span class=\"n\">_closure</span> <span class=\"n\">sum_cont_aux._rarg</span><span class=\"bp\">;</span>\n  <span class=\"n\">_x_2</span>\n</code></pre></div>\n<p>I'm not sure it can do any better than this unless <code>sum_cont_aux</code> were to be specialized to a particular list.</p>\n<p>But this doesn't have any bearing on <code>#reduce</code>, just to be clear.</p>",
        "id": 416866387,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1705698023
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/270676-lean4/topic/Term.20reduction.20order/near/416865966\">said</a>:</p>\n<blockquote>\n<p>The VM used in #eval can do TCO. The compiled code is basically at the whim of the C compiler with respect to TCO. This is one of the things that we can e.g. guarantee with the LLVM backend.</p>\n</blockquote>\n<p>Note that this is kind of sales pitchy, of course C compilers tend to be not stupid and <em>do</em> end up doing TCO, it's just about having the 100% certainty</p>",
        "id": 416868142,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1705698675
    },
    {
        "content": "<p>The “VM used in #eval” is <a href=\"https://github.com/leanprover/lean4/blob/c0f264ffe01ecbc0bb161b7eeb7cf4906970c3fe/src/library/compiler/ir_interpreter.cpp\"><code>ir_interpreter.cpp</code></a>, right? <br>\nI see code to do <a href=\"https://github.com/leanprover/lean4/blob/c0f264ffe01ecbc0bb161b7eeb7cf4906970c3fe/src/library/compiler/ir_interpreter.cpp#L586-L605\">TCO for manifest self-recursion</a>, but I am not sure I see where it would TCO a tail-call to another function, or to a closure – but maybe I am missing it?<br>\n(This would not affect just <code>#eval</code>, it’s evaluating anything that wasn’t compiled to native code, e.g. tactics defined in <code>std</code> or <code>mathlib</code>, right?)</p>",
        "id": 416873973,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1705701105
    },
    {
        "content": "<blockquote>\n<p>The “VM used in #eval” is <a href=\"https://github.com/leanprover/lean4/blob/c0f264ffe01ecbc0bb161b7eeb7cf4906970c3fe/src/library/compiler/ir_interpreter.cpp\"><code>ir_interpreter.cpp</code></a>, right?</p>\n</blockquote>\n<p>right</p>\n<blockquote>\n<p>I see code to do <a href=\"https://github.com/leanprover/lean4/blob/c0f264ffe01ecbc0bb161b7eeb7cf4906970c3fe/src/library/compiler/ir_interpreter.cpp#L586-L605\">TCO for manifest self-recursion</a>, but I am not sure I see where it would TCO a tail-call to another function, or to a closure – but maybe I am missing it?</p>\n</blockquote>\n<p>I don't think it does that, in general the IR interpreter is not very well optimized (which we definitely should work on!), for example it is more friendly to the branch predictor to use a different model of execution than this and many other things that we could try to do.</p>\n<blockquote>\n<p>(This would not affect just <code>#eval</code>, it’s evaluating anything that wasn’t compiled to native code, e.g. tactics defined in <code>std</code> or <code>mathlib</code>, right?)</p>\n</blockquote>\n<p>Indeed! That's why it would be good to put work into making it faster (or alternatively having a cool copy and patch JIT that runs fast and produces good enough code!)</p>",
        "id": 416877132,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1705702307
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306601\">Kyle Miller</span> <a href=\"#narrow/stream/270676-lean4/topic/Term.20reduction.20order/near/416865710\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"407274\">James Gallicchio</span> I guess I don't understand what you meant by \"runtime\" since Shreyas was talking about <code>#reduce</code>. Do you mean VM evaluation (<code>#eval</code>) or compiled code evaluation? The compiler for those definitely has TCO.</p>\n</blockquote>\n<p>Sorry this one's my fault. Lately I have been doing some PL formalization and gotten into the habit of using #reduce because it works well with unexpanders, as opposed to #eval which insists on showing me the raw terms.</p>",
        "id": 416877646,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1705702497
    }
]