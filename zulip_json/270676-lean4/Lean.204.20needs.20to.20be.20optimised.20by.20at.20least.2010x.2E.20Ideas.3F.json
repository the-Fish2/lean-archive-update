[
    {
        "content": "<p>Coming from a software developer background rather than an academic math background. I am viewing Lean as a piece of software. In that respect my observations are that it needs a great deal of optimisation. Open source projects have the habit of building up inefficiencies over time. </p>\n<p>For example, the built version of Mathlib, is several GB and takes several GB of RAM to load in and several seconds to load. That is not the fault of mathlib, but rather it must be the software and data-structures it is built upon. They were probably fine to begin with but with huge libraries I think they need updating.</p>\n<p>When Mathlib and other libraries get bigger this is only going to get worse.</p>\n<p>Can we throw some ideas around to see if we can think of ways to make it more memory efficient?</p>\n<p>Some ideas I have are (perhaps some are already implemented)</p>\n<ul>\n<li>JIT compilation of libraries. Libraries are compiled on the fly only when they are needed. (e.g. when you import Mathlib, it could just load in a list of every function. Then when you call a particular function, it could compile, or download, the particular library it needs , Algebra, say, and cache it for later, then remove ones that haven't been used for a while).</li>\n<li>Olean files only moved to RAM when needed. (e.g. when you import Mathlib - don't instantly move it all to RAM0</li>\n<li>Improve the internal data-structures to be more efficient</li>\n<li>Improve repetition in files by referencing external indexes</li>\n<li>Improve cases where tactics like \"simp\" are expanded inefficiently. </li>\n<li>Move some of Lean processing to the GPU(?) probably difficult as it's not suited for parallelism.</li>\n<li>Olean files stored in a compressed format and decompressed when needed. (I get 3x memory saving just by storing the olean files as ZIP on disk)</li>\n</ul>\n<p>Any other ideas? Are there any \"low hanging fruit\" that could cut the footprint in half?</p>",
        "id": 446209269,
        "sender_full_name": "Mr Proof",
        "timestamp": 1719022493
    },
    {
        "content": "<p>Currently you have to <code>require</code> the whole Mathlib, even if you only need Mathlib.Tactic. It would be good to have the ability to select a subdirectory.</p>\n<p>Sorry if this isn't the right place to talk about it.</p>",
        "id": 446214789,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1719027278
    },
    {
        "content": "<p>The original question seems to presuppose that no one is thinking about and working on all these things. Perhaps read the FRO roadmap?</p>",
        "id": 446215645,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1719028138
    },
    {
        "content": "<p>Regarding <code>require</code> and Mathlib: the subdirectories do not at all reflect the import structure, and I expect there are very few subsets of the directories (besides subsets close to all of Mathlib) which would work without the complement.</p>",
        "id": 446215759,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1719028240
    },
    {
        "content": "<p>If you want to work on that, there is massive amounts of work to be done simplifying and streamlining the import structure of Mathlib (perhaps one day enabling partial <code>require</code>) and assistance with this is appreciated.</p>",
        "id": 446215817,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1719028303
    },
    {
        "content": "<p>It's also worth being aware that making changes to fundamental aspects of Lean is a challenging process, and you need substantial experience with the ecosystem to be able to make a positive contribution. Work on technical debt in Mathlib, and contributing high quality documentation, are probably better things for new contributors to be thinking about.</p>",
        "id": 446215995,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1719028477
    },
    {
        "content": "<p>Yes, indeed the FRO says <strong>Scalability Enhancements</strong> but I think it's good to have a discussion where people can all throw in their ideas. Perhaps the people working on this will find out something they didn't think about. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> The more ideas the better IMO.<br>\n(I did  a search and didn't find any similar discussions)</p>\n<p>BTW, is Lean all made by volunteers or is there an in-house team at Microsoft(?) who work on the <del>kernel</del> compiler?</p>",
        "id": 446216192,
        "sender_full_name": "Mr Proof",
        "timestamp": 1719028616
    },
    {
        "content": "<p>Latest Lean code include license header of Amazon.</p>",
        "id": 446222622,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1719033327
    },
    {
        "content": "<p>Lean FRO must have been funded by some foundation.</p>",
        "id": 446222690,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1719033368
    },
    {
        "content": "<p>By the way, I am also interested in Lean's support for GPUs and parallel processing - GPUs may not be useful for proofs, but they are useful for scientific computing.</p>",
        "id": 446222739,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1719033428
    },
    {
        "content": "<p>About point 2, oleans aren't ever moved to RAM, they're just <a href=\"https://en.wikipedia.org/wiki/Memory-mapped_file\">mmapped</a>. And mathlib already uses olean compression on the wire, but they get decompressed on disk because otherwise you can't mmap them.</p>",
        "id": 446240836,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1719042487
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"626349\">Asei Inoue</span> <a href=\"#narrow/stream/270676-lean4/topic/Lean.204.20needs.20to.20be.20optimised.20by.20at.20least.2010x.2E.20Ideas.3F/near/446222622\">said</a>:</p>\n<blockquote>\n<p>Latest Lean code include license header of Amazon.</p>\n</blockquote>\n<p>That's because Leo switched from MSR to Amazon, the rest of the FRO is not Amazon employees.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"725689\">Mr Proof</span> <a href=\"#narrow/stream/270676-lean4/topic/Lean.204.20needs.20to.20be.20optimised.20by.20at.20least.2010x.2E.20Ideas.3F/near/446216192\">said</a>:</p>\n<blockquote>\n<p>BTW, is Lean all made by volunteers or is there an in-house team at Microsoft(?) who work on the kernel?</p>\n</blockquote>\n<p>To my knowledge there is nobody working at Microsoft that does large contributions to the Lean compiler itself anymore. There is also basically nobody working actively on the kernel, the kernel is finished, it has been barely touched for a long time. As to who is working on the Lean compiler, that's the FRO.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"626349\">Asei Inoue</span> <a href=\"#narrow/stream/270676-lean4/topic/Lean.204.20needs.20to.20be.20optimised.20by.20at.20least.2010x.2E.20Ideas.3F/near/446222690\">said</a>:</p>\n<blockquote>\n<p>Lean FRO must have been funded by some foundation.</p>\n</blockquote>\n<p>You can read on our website which foundations etc are funding the FRO.</p>",
        "id": 446245425,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1719044648
    },
    {
        "content": "<p>To continue with Kim's thought, while valiant efforts are sporadically made to simplify the dependency structure of Mathlib, as I understand it they tend to be ad hoc and to work chiefly at file level. It could be a very nice computer-sciencey project to extract the theorem-level dependency graph and attack it with the latest in network algorithms.</p>",
        "id": 446246110,
        "sender_full_name": "A.",
        "timestamp": 1719045268
    },
    {
        "content": "<p>File level dependencies are how lean works right now, and I'm not aware of plans to change that. It would be interesting to have some kind of automated analysis that could flag when heavy dependencies are only used by a small fraction of the declarations in a file, for example</p>",
        "id": 446246837,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1719045861
    },
    {
        "content": "<p>Extracting the theorem level dependency graph is definitely possible with a meta program that just looks at all theorem statements + proofs and figures out dependencies based on that. One thing to keep in mind here however is that fully elaborated Lean terms do not contain references to the syntax declarations (such as math notation or mroe importantly tactics) that they used anymore. This means that while a tactic can produce a proof term that looks very simple it might have required some part of a library in order to do so and you are not seeing that library anymore now.</p>",
        "id": 446246969,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1719045966
    },
    {
        "content": "<p>Is that something lean would be interested in tracking in the future, you think, Henrik?</p>",
        "id": 446247253,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1719046254
    },
    {
        "content": "<p>In fact, the issue of \"oleans for syntax\" has appeared in several discussions.</p>",
        "id": 446247350,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1719046347
    },
    {
        "content": "<p>I don't know about that. I do know that there is some demand for this in other features like some Mathlib linters but I'm aware of no movement to change this currently.</p>",
        "id": 446247364,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1719046365
    },
    {
        "content": "<p>We already have data on the 'hidden edges' caused by notations and tactics though, that's <code>noshake.json</code></p>",
        "id": 446303414,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1719079597
    },
    {
        "content": "<p>Isn't notation information visible in the infotree?</p>",
        "id": 446304061,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1719079959
    },
    {
        "content": "<p>I would expect it to only be things like positivity extensions (which have no syntax at the caller) referring to lemmas in an earlier file that are neither in the infotree nor the proof term</p>",
        "id": 446304138,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1719080004
    },
    {
        "content": "<p>(And I think the right thing to do there is record the used extension names in the proof in some way)</p>",
        "id": 446304195,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1719080037
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/270676-lean4/topic/Lean.204.20needs.20to.20be.20optimised.20by.20at.20least.2010x.2E.20Ideas.3F/near/446304061\">said</a>:</p>\n<blockquote>\n<p>Isn't notation information visible in the infotree?</p>\n</blockquote>\n<p>Yes, but the infotree is not stored</p>",
        "id": 446304695,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1719080287
    },
    {
        "content": "<p>also, even in a live elaboration session lean isn't very good at recording what parts of the state are actually used. The most accurate method is the obvious one: comment out imports until something breaks</p>",
        "id": 446304744,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1719080323
    },
    {
        "content": "<p>I think a useful tool would be a variant of <code>shake</code> that reported if an import was not used in the first <code>N</code> lines (e.g. N=500) of a file. These would be obvious targets for splitting files, and you could crank down <code>N</code> (or use a fraction of the file length).</p>",
        "id": 446365356,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1719115852
    },
    {
        "content": "<p>I was thinking of having a go at making a little C command line tool, that basically just read all the Lean files, and searched for the words \"import\" to make a list of the libraries used in a file. That could be run pretty quickly I imagine to make some sort of tree dependency graph. Which you could feed into something like Mathematica to give a graphical view.<br>\nAlso, it could search for the words like \"def\" , \"lemma\", \"theorem\" etc. to make a list of every definition in a file. This could all be done without parsing anything. <br>\nWhile not being as accurate as writing this in Lean code I imagine it would run a lot faster(?) <br>\nOr would it be \"necessary to break out Emacs and modify that Perl script\"?</p>",
        "id": 446368666,
        "sender_full_name": "Mr Proof",
        "timestamp": 1719118317
    },
    {
        "content": "<p>We already have <code>import-graph</code> written in Lean that can export to <code>dot</code>, hence generate <code>.pdf</code>.</p>",
        "id": 446377489,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1719123179
    },
    {
        "content": "<p>It runs fast enough (large invocations with <code>pdf</code> output are slow because of <code>dot</code> choosing locations for nodes, not because of Lean is slow in generating the graph) and is 100% accurate.</p>",
        "id": 446377688,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1719123260
    }
]