[
    {
        "content": "<p>Hi there! I am looking into having a blueprint for one of the projects that we are working on, and would like it to be hosted on github itself. I figured I would keep things simple, and just upload the documentation generated by doc-gen4 and the blueprint generated by Patrick Massot's plastex plugin to the github repository, and browse it using github Pages. The issue I have is that doc-gen4 generates some pretty big '.bmp' files, which would require git-lfs. Is there a simple way around this? Should I be doing things differently? Or should I just go ahead and use git-lfs?</p>",
        "id": 406423544,
        "sender_full_name": "Ian Jauslin",
        "timestamp": 1701913652
    },
    {
        "content": "<p>Yes. Basically, don't dump the files in the first place.</p>",
        "id": 406490222,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701936812
    },
    {
        "content": "<p>GitHub pages has two modes:</p>\n<ul>\n<li>Serve a website from the contents of a git repo</li>\n<li>Serve a website from the output of a build step that takes a git repo as input</li>\n</ul>\n<p>The second one means the bmp file is never committed, which avoids the size issues</p>",
        "id": 406506672,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1701942636
    },
    {
        "content": "<p>The second option is what's used in <a href=\"https://github.com/teorth/pfr\">the PFR project</a>, and the same as the one I explained in <a href=\"#narrow/stream/270676-lean4/topic/Documentation.20Generation.20in.20Lean4/near/405949149\">another thread</a>.</p>",
        "id": 406551847,
        "sender_full_name": "Utensil Song",
        "timestamp": 1701958739
    },
    {
        "content": "<p>Thank you! I didn't expect github would do all of this for free. I'm impressed! I'll set it up.</p>",
        "id": 406567666,
        "sender_full_name": "Ian Jauslin",
        "timestamp": 1701963163
    },
    {
        "content": "<p>Why does <code>doc-gen4</code> need <code>bmp</code> files?</p>",
        "id": 411099873,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1704326252
    },
    {
        "content": "<p>Its a trick to encourage github to compress them better IIRC, they aren't really bmp's but contain most of the data needed for search etc</p>",
        "id": 411101590,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1704327099
    },
    {
        "content": "<p>Yep, the reason is that the github pages server will gzip any file (via <code>Content-Encoding</code>) with a bmp extension, but won't do so for json</p>",
        "id": 411102843,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704327821
    },
    {
        "content": "<p>How long is the decompression time?</p>",
        "id": 411102896,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704327844
    },
    {
        "content": "<p>It's handled by the browser natively, so who knows</p>",
        "id": 411102932,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704327855
    },
    {
        "content": "<p>I think GitHub pages will do so for <code>.json</code> as well? At least that's what we found for the project I work on recently.</p>",
        "id": 411104146,
        "sender_full_name": "Julian Berman",
        "timestamp": 1704328550
    },
    {
        "content": "<p>(Try <code>http get https://bowtie.report/draft2019-09.json</code>, it gets <code>Content-Encoding: gzip</code>).</p>",
        "id": 411104212,
        "sender_full_name": "Julian Berman",
        "timestamp": 1704328573
    },
    {
        "content": "<p>Maybe this changed recently; certainly it used to not be gzipped</p>",
        "id": 411104554,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704328746
    },
    {
        "content": "<p>Maybe. It's certainly quite poorly documented and there's some random set of things it gzips, we started with <code>.jsonl</code>, and that it will indeed not gzip.</p>",
        "id": 411104686,
        "sender_full_name": "Julian Berman",
        "timestamp": 1704328805
    },
    {
        "content": "<p>But yeah <code>.json</code> I think works fine now.</p>",
        "id": 411104715,
        "sender_full_name": "Julian Berman",
        "timestamp": 1704328823
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Hosting.20doc.20on.20github.20and.20large.20files/near/411102932\">said</a>:</p>\n<blockquote>\n<p>It's handled by the browser natively, so who knows</p>\n</blockquote>\n<p>I just wonder if this is one of the reasons why the docs are slow, although downloading something big won't help much either</p>",
        "id": 411104920,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704328928
    },
    {
        "content": "<p>Chrome refuses to reveal how much time is spent downloading vs gzipping</p>",
        "id": 411105021,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704328988
    },
    {
        "content": "<p>I think the idea is that the gzipping happens in realtime while the download is happening</p>",
        "id": 411105039,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1704329003
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284160\">Eric Rodriguez</span> <a href=\"#narrow/stream/113488-general/topic/Hosting.20doc.20on.20github.20and.20large.20files/near/411104920\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Hosting.20doc.20on.20github.20and.20large.20files/near/411102932\">said</a>:</p>\n<blockquote>\n<p>It's handled by the browser natively, so who knows</p>\n</blockquote>\n<p>I just wonder if this is one of the reasons why the docs are slow, although downloading something big won't help much either</p>\n</blockquote>\n<p>The downloading and gzipping is a non issue. You only download the data once, afterwards it remains in your cache. If there is something slow it's the JavaScript that processes the several MB of JSON, tho I spent quite a bit of time making it eh...less slow. Do you have a particular feature that you think is too slow</p>",
        "id": 411150610,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704358892
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Hosting.20doc.20on.20github.20and.20large.20files/near/411105021\">said</a>:</p>\n<blockquote>\n<p>Chrome refuses to reveal how much time is spent downloading vs gzipping</p>\n</blockquote>\n<p>And yeah even if it was downloading and gzipping all the time I would bet that on a modern computer with the internet speeds available to the average person the gzipping is much faster than the download if it is indeed implemented natively</p>",
        "id": 411151536,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704359192
    },
    {
        "content": "<p>Search autocomplete and the /find page to me are not the fastest</p>",
        "id": 411152596,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704359653
    },
    {
        "content": "<p>With the autocomplete there is an intentional debounce delay such that it doesn't unnecessarily perform autocompletion all the time and end up being uninteractive because of that. But the debouncing delay is an arbitrary number that I intentionally picked a little high. I can try to fine tune it to fit closer to a real time experience.</p>",
        "id": 411161496,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704363192
    },
    {
        "content": "<p>Is it easy to toy with this number? I understand that uninteractiveness is to be avoided but real-time autocomplete is always nice, especially with fzf-like bolding; I'm likely asking far too much though!</p>",
        "id": 411161786,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704363308
    },
    {
        "content": "<p>its the 300 in this line: <a href=\"https://github.com/leanprover/doc-gen4/blob/eab9173b56295c3dadf46e104ab342060cbe2af8/static/search.js#L149\">https://github.com/leanprover/doc-gen4/blob/eab9173b56295c3dadf46e104ab342060cbe2af8/static/search.js#L149</a></p>",
        "id": 411162012,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704363393
    },
    {
        "content": "<p>Okay I tuned it way down to a delay that corresponds to 60hz so instant for an human eye. That seems to work fine on the std4 dataset, I'll push the commit and we can check how it feels on the real mathlib dataset.</p>",
        "id": 411164217,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704364344
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"284160\">@Eric Rodriguez</span> better?</p>",
        "id": 411182689,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704372210
    },
    {
        "content": "<p>it's incredible!!</p>",
        "id": 411183616,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704372618
    },
    {
        "content": "<p>Doing some more measurements, I'm sorry for the chrome people: On firefox the string matcher in the search runs in approximately 80-120ms, on chrome the same JS goes at 210 to 230 :(</p>",
        "id": 411201822,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704379739
    },
    {
        "content": "<p>And v8 said it was a good engine :b</p>",
        "id": 411202054,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704379837
    },
    {
        "content": "<p>Im quite surprised myself yeah</p>",
        "id": 411203137,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1704380257
    }
]