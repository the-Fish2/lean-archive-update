[
    {
        "content": "<p>I've formalized software floating point interval arithmetic.  Currently, I have ordered field operations (+, -, *,  /, &lt;, abs), power series evaluation of <code>exp</code>, <code>log</code>, and powers, and a few extras (scale by a power of two).  The main types are</p>\n<ol>\n<li><a href=\"https://github.com/girving/ray/blob/a28efd5373687a75602a16b34534f41010b941a7/Ray/Approx/Floating/Basic.lean#L25\"><code>Floating</code></a>: 64+64-bit normalized floating point, where<code>n : Int64</code> and <code>s : UInt64</code> represent the real number <code>n * 2^(s - 2^63)</code>.   <code>n</code> is normalized (has high bit set) unless <code>s = 0</code>.  There are <code>nan</code> values to handle overflow.</li>\n<li><a href=\"https://github.com/girving/ray/blob/c8ccce697b4461ce72049c9ddc066b99032acea0/Ray/Approx/Interval/Basic.lean#L22\"><code>Interval</code></a>: Two floating point numbers <code>[lo, hi]</code> representing a nonempty interval (possibly <code>[nan, nan]</code> representing <code>univ</code>).</li>\n</ol>\n<p>Operations on <code>Interval</code> are all conservative (guaranteed to approximate exact real computations).  Everything is built on top of fixed precision integer operations with no new axioms (there is no trust of the native <code>Float</code> type currently).  There are (almost) no results saying that the intervals are tight, so it's empirical whether they expand too much, and in various places I'm not happy with the precision (in particular <a href=\"https://github.com/girving/ray/blob/a28efd5373687a75602a16b34534f41010b941a7/Ray/Approx/Series.lean#L511\">for power series</a>, though I know some of the reasons why).</p>\n<p>I'm going to use this next for two things:</p>\n<ol>\n<li>An <code>approx</code> tactic which proves real constant formulas by moving them over to <code>Interval</code>.</li>\n<li>Some Mandelbrot set renders.</li>\n</ol>\n<p>I'd be curious if anyone has recommendations for the best way to implement the <code>approx</code> tactic.  I could do it by pure pattern matching, but my guess is pushing a bunch of things into a <code>DiscrTree</code> is best.  If anyone has a paragraph-length suggestion of how they'd go about a prototype for that, I'd be eager to see get advice.</p>",
        "id": 419936247,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707170586
    },
    {
        "content": "<p>Did you look at the existing tactics in Coq and Isabelle?</p>",
        "id": 419936564,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1707170722
    },
    {
        "content": "<p>Currently I have a bunch of lemmas registered for <code>mono</code> which lets me dispatch interval computations.  <a href=\"https://github.com/girving/ray/blob/a28efd5373687a75602a16b34534f41010b941a7/Ray/Approx/Approx.lean#L150C1-L153C64\">For example</a>,</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[</span><span class=\"n\">mono</span><span class=\"kd\">]</span> <span class=\"kd\">lemma</span> <span class=\"n\">mem_approx_mul</span> <span class=\"o\">[</span><span class=\"n\">Mul</span> <span class=\"n\">R</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">Mul</span> <span class=\"n\">A</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">Approx</span> <span class=\"n\">A</span> <span class=\"n\">R</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">ApproxMul</span> <span class=\"n\">A</span> <span class=\"n\">R</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">R</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">A</span><span class=\"o\">}</span>\n    <span class=\"o\">(</span><span class=\"n\">ax</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">∈</span> <span class=\"n\">approx</span> <span class=\"n\">x</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">yb</span> <span class=\"o\">:</span> <span class=\"n\">b</span> <span class=\"bp\">∈</span> <span class=\"n\">approx</span> <span class=\"n\">y</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">*</span> <span class=\"n\">b</span> <span class=\"bp\">∈</span> <span class=\"n\">approx</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"bp\">*</span> <span class=\"n\">y</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">apply</span> <span class=\"n\">subset_approx_mul</span> <span class=\"o\">(</span><span class=\"n\">singleton_subset_iff.mpr</span> <span class=\"n\">ax</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">singleton_subset_iff.mpr</span> <span class=\"n\">yb</span><span class=\"o\">)</span>\n  <span class=\"n\">simp</span> <span class=\"n\">only</span> <span class=\"o\">[</span><span class=\"n\">mul_singleton</span><span class=\"o\">,</span> <span class=\"n\">image_singleton</span><span class=\"o\">,</span> <span class=\"n\">mem_singleton_iff</span><span class=\"o\">]</span>\n</code></pre></div>",
        "id": 419936568,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707170725
    },
    {
        "content": "<p>Aren't those eligible to become <code>gcongr</code> lemmas?</p>",
        "id": 419936740,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1707170806
    },
    {
        "content": "<p>I should clarify that I know conceptually how to implement the tactic, so I'm asking if people have advice on Lean details.  But admittedly I haven't formulated a very clear question.</p>",
        "id": 419936762,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707170814
    },
    {
        "content": "<p>No, gcongr is very restrictive: the types have to match on the two sides.  Here the congruence is between reals and <code>Interval</code>.</p>",
        "id": 419936818,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707170841
    },
    {
        "content": "<p>E.g., if I want to turn the addition of two rational numbers into intervals, I need to call <code>Interval.ofRat</code> twice, use its associated approximation lemma <a href=\"https://github.com/girving/ray/blob/a28efd5373687a75602a16b34534f41010b941a7/Ray/Approx/Interval/Conversion.lean#L59\"><code>Interval.approx_ofRat</code></a> to show the intervals contain the results, then use <a href=\"https://github.com/girving/ray/blob/a28efd5373687a75602a16b34534f41010b941a7/Ray/Approx/Approx.lean#L29\"><code>approx_add</code></a> or <a href=\"https://github.com/girving/ray/blob/a28efd5373687a75602a16b34534f41010b941a7/Ray/Approx/Approx.lean#L140\"><code>mem_approx_add</code></a> to show that the addition is conservative.</p>",
        "id": 419937228,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707171021
    },
    {
        "content": "<p>Have you compared the performance as an <code>aesop</code> wrapper rather than as an <code>apply_rules</code> wrapper (which is what <code>mono</code> is)?</p>",
        "id": 419968105,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1707189698
    },
    {
        "content": "<p>Sample code setting it this kind of thing as an <code>aesop</code> wrapper: <a href=\"https://github.com/teorth/pfr/blob/master/PFR/Tactic/Finiteness.lean\">https://github.com/teorth/pfr/blob/master/PFR/Tactic/Finiteness.lean</a></p>",
        "id": 419968255,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1707189788
    },
    {
        "content": "<p>Thank you!  No, I haven't profiled mono here, and I do expect the aesop version would be faster.</p>",
        "id": 420001673,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707210032
    },
    {
        "content": "<p>Two Isabelle references about their corresponding tactic: <a href=\"https://www.researchgate.net/publication/238740304_Proving_Inequalities_over_Reals_with_Computation_in_IsabelleHOL\">https://www.researchgate.net/publication/238740304_Proving_Inequalities_over_Reals_with_Computation_in_IsabelleHOL</a> for the short version, and <a href=\"https://home.in.tum.de/~hoelzl/documents/hoelzl09diplomathesis.pdf\">https://home.in.tum.de/~hoelzl/documents/hoelzl09diplomathesis.pdf</a> for the expanded version.</p>",
        "id": 420003177,
        "sender_full_name": "Sébastien Gouëzel",
        "timestamp": 1707210608
    },
    {
        "content": "<p>For Coq interval arithmetic, it may be worth having a look at <a href=\"https://coqinterval.gitlabpages.inria.fr\">https://coqinterval.gitlabpages.inria.fr</a>, which, in my impression, has better performance than the Isabelle implementation suggested by Sébastien. Also, Isabelle has <a href=\"https://www.isa-afp.org/entries/Affine_Arithmetic.html\">affine arithmetic</a> that could be useful when facing linear dependence between variables.</p>",
        "id": 420024293,
        "sender_full_name": "Wenda Li",
        "timestamp": 1707218003
    },
    {
        "content": "<p>The Coq interval tactic clocks in at ~40k LOC (a third of Lean 4), so don't hold your horses.</p>\n<p>(Edit: I just realised that this is entirely the wrong metaphor. <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span> Well, you know what I mean.)</p>",
        "id": 420039592,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1707223692
    },
    {
        "content": "<p>I mean, I've already done all the hard work: I have fully formalized interval arithmetic.  The tactic is just calling the appropriate lemmas.</p>",
        "id": 420039685,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707223723
    },
    {
        "content": "<p>But probably I am going to get distracted and make a Mandelbrot picture first... :)</p>",
        "id": 420040027,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707223822
    },
    {
        "content": "<p>The reference I gave is among other things interesting for practical tricks to compute quickly <code>sqrt</code>, <code>arctan</code>,  <code>cos</code> and so on in a pretty efficient way, better than naive truncation of the Talor series (see Section 4.4 there)</p>",
        "id": 420041579,
        "sender_full_name": "Sébastien Gouëzel",
        "timestamp": 1707224329
    },
    {
        "content": "<p>Yes, it's possible to have way tighter intervals than what I'm doing, but if one just wants 10 significant digits the basic stuff is okay.  And speed is not important for evaluating simple formulas (it'll be more important in the heavy rendering applications).</p>",
        "id": 420041940,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707224420
    },
    {
        "content": "<p>The Coq tactic (<a href=\"https://hal.science/hal-00180138/file/article.pdf\">paper</a>) uses reflection with a specialised integer representation and does something called \"bisection\". But I can't tell how important these features are.</p>",
        "id": 420043688,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1707224959
    },
    {
        "content": "<p><code>bisection</code> presumably just means chopping the intervals in half and reevaluating.  One typically doesn't need to do that if  one starts with point-like intervals: it's for proving that large regions are correct.  I'm mostly intending to use this in the point-like case, including for rendering, and using theory to give me the region stuff (in particular the Koebe quarter theorem for Mandelbrot renders).</p>",
        "id": 420043984,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707225055
    },
    {
        "content": "<p>But the code does work sensibly for large intervals.  For division, exp, and log I handle them by using monotonicity to reduce to the point-like case, though.</p>",
        "id": 420044092,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707225095
    },
    {
        "content": "<p>I think reflection just means the normal \"proof by reflection\" approach, which is also what I'm referring to here.</p>",
        "id": 420044402,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707225199
    },
    {
        "content": "<p>E.g., to evaluate <code>exp [a,b]</code> I do separate argument reduction and Taylor series evalutions for <code>exp a</code> and <code>exp b</code> (since the multiple of <code>log 2</code> one wants to subtract may be different) and then take the union.</p>",
        "id": 420044597,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707225263
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"514145\">Geoffrey Irving</span> <a href=\"#narrow/stream/113488-general/topic/Verified.20software.20floating.20point/near/420044402\">said</a>:</p>\n<blockquote>\n<p>I think reflection just means the normal \"proof by reflection\" approach, which is also what I'm referring to here.</p>\n</blockquote>\n<p>Yes, it's proof by reflection. This doesn't tend to work so well in Lean because the Lean kernel is very slow compared to Coq. However, if the tactic mostly does computations on <code>Nat</code>, which is builtin and backed by GMP-style bignums, then proof by reflection is maybe fine.</p>",
        "id": 420070833,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1707232828
    },
    {
        "content": "<p>Yes, for the Mandelbrot stuff I'll get around that via by trusting the compiler.</p>",
        "id": 420072239,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1707233240
    }
]