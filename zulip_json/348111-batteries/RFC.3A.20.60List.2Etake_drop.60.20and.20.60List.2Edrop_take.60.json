[
    {
        "content": "<p>This theorem just landed in Std from <a href=\"https://github.com/leanprover/std4/pull/272\">std4#272</a>, upstreaming a variety of useful List theorems from Mathlib. I just noticed this theorem:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">drop_take</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">take</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>It seems to me this theorem (which is <em>not</em> a simp) is much more useful as a rewrite rule in the other direction:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">take_drop</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">take</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"n\">l</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>The reason is that the lhs catches all <code>take</code>-<code>drop</code> combinations. For the <code>drop</code>-<code>take</code> combination, this lemma seems more useful for the same reason.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">drop_take</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">drop</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">-</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">n</span> <span class=\"n\">l</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>With omega in core, we don't need to worry as much about adding <code>Nat</code> operations on the rhs. So I think the two proposed alternatives are objectively better.</p>\n<p>I'm asking before doing a PR because the original theorem came from Mathlib and the proposed changes might be disruptive downstream.</p>",
        "id": 428435321,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711160962
    },
    {
        "content": "<p>If you have both your<code>take_drop</code> and <code>drop_take</code> (which I agree seem plausible), won't that loop? It seems we have to pick one order as the normal form and only rewrite the other</p>",
        "id": 429073476,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1711193847
    },
    {
        "content": "<p>Or are you only proposing them as rw rules to be used manually? Then this isn't a concern of course.</p>",
        "id": 429073552,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1711193894
    },
    {
        "content": "<p>Isn't the usual rule to put the simpler term on the RHS?</p>",
        "id": 429076668,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1711196861
    },
    {
        "content": "<p>It sounds like you're claiming the opposite rule of \"put the more syntactically general term on the LHS\"</p>",
        "id": 429076725,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1711196886
    },
    {
        "content": "<p>Yes, that is one good general rule, but not the only one, and sometimes it's not clear what's best.<br>\nI'm generally wairy of non-linear LHSs (those where one variable occurs multiple times), they are very brittle and often get in the way of confluence.  I experimented a bit with checking local confluence of simp lemmas in <a href=\"https://github.com/nomeata/lean-simplc\">https://github.com/nomeata/lean-simplc</a> and non-linearity was one main cause for non-confluence.</p>\n<p>I think I'd prefer the <code>drop_take</code> rule shown last; it applies generally, and <code>m - n</code> is in some sense simpler, because smaller than <code>m + n</code>. And <code>take</code> of <code>drop</code> seems to be the natural order, first removing unwanted elements, and then selecting those to keep.</p>\n<p>But that's just gut feeling; the interplay between the full set of simp rules matter.</p>",
        "id": 429084091,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1711203021
    },
    {
        "content": "<p>Neither is intended as a simp, the original form is also not simp. My question is why not use the direction that makes more sense for rewrites. I think these (together with <code>take_take</code> and <code>drop_drop</code>) are meant to allow sequences of <code>drop</code>s and <code>take</code>s to be reorganized into a single <code>drop</code>-<code>take</code> or <code>take</code>-<code>drop</code>. </p>\n<p>I can't see an objective reason to prefer <code>drop</code>-<code>take</code> or <code>take</code>-<code>drop</code>, but we could just pick one as a normal form and use that as guidance. <span class=\"user-mention\" data-user-id=\"470149\">@Joachim Breitner</span> seems to prefer <code>take</code>-<code>drop</code>. In that case, it makes sense to replace the current <code>drop_take</code> with</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">drop_take</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">drop</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">-</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">n</span> <span class=\"n\">l</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>I wouldn't mark it simp but it would make sense for users to manually add it when needed.</p>",
        "id": 429117531,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711229367
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 429118041,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711229685
    },
    {
        "content": "<blockquote>\n<p>My question is why not use the direction that makes more sense for rewrites.</p>\n</blockquote>\n<p>Perhaps a natural conclusion of this is that _maybe_ it's desirable to be able to name a lemma in one direction, but mark it as <code>simp</code> in the other (in cases where it makes sense to be a <code>simp</code> lemma in the first)</p>",
        "id": 429126881,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1711237134
    },
    {
        "content": "<p>Yes, maybe. But I think the situation is more complex.</p>\n<p>My original point is that we can sometimes disregard adding arithmetical complexity because they can be postponed and resolved easily using awesome tools like <code>omega</code>.</p>\n<p>Joachim brought up an excellent point where the proposed <code>drop_take</code> lemma is actually simplifying. If we count list operations, assuming the \"generic\" case where <code>n ≤ m</code> and <code>m + n ≤ l.length</code>, the lhs takes <code>m + n</code> ops whereas the rhs takes <code>(m - n) + n = m</code> ops. Of course, one needs to take into account calculating <code>m - n</code>. This does take the missing <code>n</code> ops using basic successor arithmetic, but in reality it takes <code>O(log(m+n))</code> ops which is dwarfed by the list operations.</p>\n<p>Anyway, it seems there could be a greater discussion about the general issue here, but probably in another thread with broader audience.</p>",
        "id": 429163961,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711263557
    },
    {
        "content": "<p>I think it would be best to just not try to normalize these</p>",
        "id": 429164059,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1711263663
    },
    {
        "content": "<p>I think that matches the thumbed up proposal above to change the lemma so it is more applicable but not mark it as simp.</p>\n<p>Does that make sense to you <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> and <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span>?</p>",
        "id": 429164645,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711264164
    },
    {
        "content": "<p>I would not replace the original, both variants look useful</p>",
        "id": 429164720,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1711264237
    },
    {
        "content": "<p>For the sake of avoiding primes or other meaningless annotations, do you think it makes sense to reword the original <code>drop_take</code> as mentioned above:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">take_drop</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">take</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"n\">l</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>Of course, neither this nor the proposed <code>drop_take</code> would be maked as simp lemmas.</p>",
        "id": 429164983,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711264489
    },
    {
        "content": "<p>One challenge with these lemmas is that there are many <code>List</code> (and other data structures) is that there are many operations and so even the pairwise combination is quite large.   I think for <code>List</code>, ensuring there are good simp rules for <code>(op ..).get?</code> and then relying on <code>List.ext</code> is a good option for expressions involving <code>take</code>/<code>drop</code>/<code>append</code>.</p>\n<p>I'm not sure what's best to do for operations such as <code>List.filter</code>, and longer term we likely will want something with better automation.</p>",
        "id": 429462247,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1711385094
    },
    {
        "content": "<p>Another possibility would be to reduce the number of distinct list operations by grouping them based on their effect on the \"shape\" of the list. For example, <code>take</code>, <code>drop</code>, <code>dropFirst</code>, <code>dropLast</code>, and <code>eraseIdx</code> all have the effect of removing a contiguous range of indices from the list. If we had <code>eraseRange</code>, we could define all of the above as <code>abbrev</code>s in terms of <code>eraseRange</code>. If we did this for all of the List methods, we would drastically reduce the number of <code>simp</code> lemmas we need</p>",
        "id": 429718638,
        "sender_full_name": "Timo Carlin-Burns",
        "timestamp": 1711478844
    },
    {
        "content": "<p>That is an option - at the expense that running <code>simp</code> will turn simple functions the user likes to see into a something more complicated that they didn't write. <br>\nI'm wondering if having the n² lemmas is really so bad, if each of these lemmas is quickly written. This means more work in the libraries, but good <code>simp</code> behavior for the users.</p>",
        "id": 429730852,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1711483593
    },
    {
        "content": "<p>my gut is telling me that <code>List.take</code> and <code>List.drop</code> are best characterized in terms of prefixes/suffixes, not <code>List.get</code>. But I have not yet tried incorporating them into LeanColls.</p>",
        "id": 429732765,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1711484378
    },
    {
        "content": "<p><code>List.take n L = L' \\iff L'.length = min(n, L.length) \\and L' &lt;+: L</code> or something</p>",
        "id": 429733093,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1711484497
    },
    {
        "content": "<p>not very simp-friendly though</p>",
        "id": 429733134,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1711484513
    },
    {
        "content": "<p>It's good to have characteristic lemmas, but they are not a replacement for the n^2 \"successive operations\" or n*m \"operation then observation\" lemmas. More of a backup!</p>",
        "id": 429733872,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1711484796
    },
    {
        "content": "<p>if we could get automation to do</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">generalize</span> <span class=\"n\">hLtake</span> <span class=\"o\">:</span> <span class=\"n\">List.take</span> <span class=\"n\">n</span> <span class=\"n\">L</span> <span class=\"bp\">=</span> <span class=\"n\">Ltake</span> <span class=\"n\">at</span> <span class=\"bp\">*</span>\n<span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">List.take_char</span><span class=\"o\">]</span> <span class=\"n\">at</span> <span class=\"n\">hLtake</span>\n</code></pre></div>\n<p>whenever it sees <code>List.take n L</code>, I would give it a try :P</p>",
        "id": 429734882,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1711485226
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"407274\">@James Gallicchio</span>, I don't understand why we would want that. Can you give more context?</p>",
        "id": 429749169,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1711491610
    },
    {
        "content": "<p>I don't really have a context in mind for it. But I've been experimenting with reasoning about collections generically, and remember this pattern coming up. Let me look for an example.</p>",
        "id": 429752863,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1711493994
    },
    {
        "content": "<p>Belated announcement... the PR exists <a href=\"https://github.com/leanprover/std4/pull/710\">std4#710</a></p>\n<p>Right now it only deletes the old <code>drop_take</code> and replaces it by two theorems:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">take_drop</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">take</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">drop</span> <span class=\"n\">m</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">+</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"bp\">...</span>\n\n<span class=\"kd\">theorem</span> <span class=\"n\">drop_take</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">drop</span> <span class=\"n\">n</span> <span class=\"o\">(</span><span class=\"n\">take</span> <span class=\"n\">m</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">take</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">-</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">drop</span> <span class=\"n\">n</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"bp\">...</span>\n</code></pre></div>\n<p>Note that neither is simp and the old <code>drop_take</code> is now <code>Eq.symm (take_drop ...)</code>.</p>\n<p>I'm glad this discussion is happening and I'm happy to make changes accordingly. Also feel free to comment on the PR itself.</p>",
        "id": 429755529,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711495510
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/stream/348111-std4/topic/RFC.3A.20.60List.2Etake_drop.60.20and.20.60List.2Edrop_take.60/near/429730852\">said</a>:</p>\n<blockquote>\n<p>That is an option - at the expense that running <code>simp</code> will turn simple functions the user likes to see into a something more complicated that they didn't write. </p>\n</blockquote>\n<p>Is there a way, maybe with delaborators, to make sure that operations which are expressible as one of the specialized functions are pretty printed that way? I think you could get the best of both worlds of nice shorthands and streamlined reasoning</p>",
        "id": 429774322,
        "sender_full_name": "Timo Carlin-Burns",
        "timestamp": 1711508774
    },
    {
        "content": "<p>Hmm, that’s a dangerous amount of magic, I fear…</p>\n<p>The GHC simplifier has phases, so it would rewrite <code>.drop</code> to <code>eraseRange</code>, then do the main work, and at the end rewrite <code>eraseRange</code> back to <code>drop</code>if it fits. This would indeed reduce the number of lemmas needed while keeping the proof goals simple, at the expense that <code>simp</code> will do “something” even if it doesn’t do anything useful and ends up returning the same goal. </p>\n<p>And then there are more general approaches (match up to equivalences and whatnot) that may also help here, maybe we’ll get them eventually.</p>\n<p>Until then, just writing many theorems isn’t so bad, and thanks to the discrimination trees, at least it’s not going to slow down simp to have them.</p>",
        "id": 429815073,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1711531374
    },
    {
        "content": "<p>The downsides with writing many theorems from my perspective are:</p>\n<ul>\n<li>You probably want consistency across other <code>Array</code> and other sequence types so that increaases workload further.</li>\n<li>Users interested in seeing what they can prove have to look through it all.</li>\n<li>Each theorem may break when upstream changes occur.  More lemmas = more chances to break.</li>\n<li>The fragments of logic when working with arrays/lists has many undecidable subproblems (e.g., monoid word problem) so set of \"reasonable\" lemmas is probably larger than quadratic with respect to number of operations.  Practically, users will probably want lemmas involving things like taking apart a list with <code>take</code>/<code>drop</code> and then rebuilding.</li>\n</ul>\n<p>If one could write up a crisp characterization of what the proposed \"N^2\" lemmas are, then I'd feel more confident that was the correct approach.</p>\n<p>Longer term, there's also a lot of research in \"string\" theories in SMT that eventually may help with Lean automation.</p>",
        "id": 429908028,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1711559077
    },
    {
        "content": "<blockquote>\n<p>If one could write up a crisp characterization of what the proposed \"N^2\" lemmas are, then I'd feel more confident that was the correct approach.</p>\n</blockquote>\n<p>The reference to \"N^2\" should be fairly clear about this much: it's referring to the pairwise interaction of every two definitions in the API. Obviously this is very oversimplified: many pairs can't be placed close enough together to interact, and some can be placed in multiple ways. But generally speaking I think the bound is approximately correct - there are O(1) ways to combine two constants together, and in any case it is good guidance on the question \"how do I make an API that 'feels complete'\".</p>",
        "id": 429948030,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1711573002
    },
    {
        "content": "<blockquote>\n<p>The fragments of logic when working with arrays/lists has many undecidable subproblems (e.g., monoid word problem) so set of \"reasonable\" lemmas is probably larger than quadratic with respect to number of operations.</p>\n</blockquote>\n<p>I think this reasoning is incorrect. The word problem is undecidable, but it is \"finitely generated\": there are a fixed finite set of lemmas which give you the moves and there is an infinite space of ways you can combine them. We only need to give the generating set, not the full space. Most of the points in the space are not interesting anyway: we do not want a lemma that says <code>x + 0 + 0 + 0 = x</code> because we can obtain it using only lemmas in the \"generating set\" in a very straightforward way (= \"by simp\")</p>",
        "id": 429948628,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1711573238
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/348111-std4/topic/RFC.3A.20.60List.2Etake_drop.60.20and.20.60List.2Edrop_take.60/near/429948628\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>The fragments of logic when working with arrays/lists has many undecidable subproblems (e.g., monoid word problem) so set of \"reasonable\" lemmas is probably larger than quadratic with respect to number of operations.</p>\n</blockquote>\n<p>I think this reasoning is incorrect.</p>\n</blockquote>\n<p>Yes, this is incorrect reasoning: this is the free monoid, which does have decidable equality.</p>",
        "id": 429967830,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711583365
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/348111-std4/topic/RFC.3A.20.60List.2Etake_drop.60.20and.20.60List.2Edrop_take.60/near/429948628\">said</a>:</p>\n<blockquote>\n<p>The word problem is undecidable, but it is \"finitely generated\": there are a fixed finite set of lemmas which give you the moves and there is an infinite space of ways you can combine them. We only need to give the generating set, not the full space. Most of the points in the space are not interesting anyway: we do not want a lemma that says <code>x + 0 + 0 + 0 = x</code> because we can obtain it using only lemmas in the \"generating set\" in a very straightforward way (= \"by simp\")</p>\n</blockquote>\n<p>This is right, the word problem is semi-decidable and simp is a semi-decision tool: it's always right but it can fail.</p>",
        "id": 429968080,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711583520
    },
    {
        "content": "<p>It's perfectly reasonable to make complete simp rules for the word problem, non-withstanding depth limits and such.</p>",
        "id": 429968553,
        "sender_full_name": "François G. Dorais",
        "timestamp": 1711583797
    },
    {
        "content": "<p>I should have not elaborated on the decidability issue; I think that's irrelevant to the current discussion.</p>\n<p>Pragmatically, I think the number of lemmas is large and I still haven't a nice writeup of what the strategy beyond all pairwise combination of lemmas for some unspecified set of operations.  I think it'd be great to see a nice writeup.</p>",
        "id": 429969131,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1711584073
    },
    {
        "content": "<p>Just a general remark: the <code>n * m</code> lemmas about the <code>n</code> operations and the <code>m</code> observations are generally higher priority than the <code>n * n</code> lemmas. e.g. for <code>BitVec</code>, the observations are something like <code>.getLsb i</code>, <code>getMsb i</code>, <code>msb</code>, <code>toNat</code>, ...</p>\n<p>Once you have all those lemmas, you can hope that <em>often but not always</em> the proofs of the n^2 lemmas are <code>ext &lt;;&gt; simp</code> (sometimes having to hold <code>ext</code>'s hand and tell it which \"observation\" to use).</p>",
        "id": 429972752,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1711586526
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/348111-std4/topic/RFC.3A.20.60List.2Etake_drop.60.20and.20.60List.2Edrop_take.60/near/429972752\">said</a>:</p>\n<blockquote>\n<p>Just a general remark: the <code>n * m</code> lemmas about the <code>n</code> operations and the <code>m</code> observations are generally higher priority than the <code>n * n</code> lemmas. e.g. for <code>BitVec</code>, the observations are something like <code>.getLsb i</code>, <code>getMsb i</code>, <code>msb</code>, <code>toNat</code>, ...</p>\n</blockquote>\n<p>Is this a good place to draw the core / std or std / mathlib line?</p>",
        "id": 430001372,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1711605269
    },
    {
        "content": "<p>Not in my opinion. The line would be more once you get beyond just direct implications of the definitions (the <code>n * n</code> lemmas) and into more sophisticated (and mathematically interesting) properties, but I think it is more difficult to make that precise</p>",
        "id": 430001623,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1711605475
    },
    {
        "content": "<blockquote>\n<p>You probably want consistency across other Array and other sequence types so that increaases workload further.</p>\n</blockquote>\n<p>Right. But part of the (mental) work load is wondering “which lemmas do we need” and “for a given lemma, should it be simp”.</p>\n<p>The every-two-function-interaction rule helps deciding that. I imagine it would go together with a documented linear ordering of functions which gives their desired ordering, so that you know which way to go (I’d expect <code>::</code> to be the outermost because that’s the value normal form, it would probably prefer <code>map (filter …)</code> over <code>filter (map …)</code>, because one can rewrite in one direction well but not in the other, maybe a tendency to push unary operations like <code>map</code> and <code>filter</code> into binary ones like <code>++</code> … I don’t have a complete set of rules yet, but I hope they can be found). This gives guidance and should also help to keep the simp-set non-looping.</p>\n<p>Ideally (maybe I am being too optimistic or spoiled by isabelle), each of these lemmas is a two liner consisting of one extensionality or induction (maybe functional inductinon) tactic and one closing tactic (<code>by induction … &lt;;&gt; simp_all</code>), so the individual workload should be low.</p>\n<p>As for multiple types: if you have Arrays and Lists then you probably want, in this maximalists view, every lemma for lists also for arrays, and visa-verse. Plus 2×n lemmas about how <code>toArray</code> and <code>toList</code> interact with each operation. One nice thing is that a local confluence checker would, once you have the <code>toArray</code> lemma for an operation, tell you about all the missing lemmas within that type.</p>\n<p>Of course, this desire to have confluence in the simp lemma has implications that need to be weighted. It means that if <br>\nyou had both <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=List.length_replicate#doc\">docs#List.length_replicate</a>  and <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=List.replicate_add#doc\">docs#List.replicate_add</a> as simp lemmas, you also should have <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Nat.left_distrib#doc\">docs#Nat.left_distrib</a>  (and <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=List.length_append#doc\">docs#List.length_append</a>) as a simp lemma. Right now <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Nat.left_distrib#doc\">docs#Nat.left_distrib</a>  isn’t a simp lemma, and probably for a good reason, and this therefore give guidance that <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=List.replicate_add#doc\">docs#List.replicate_add</a> shouldn’t be a simp lemma either. I find that helpful.</p>",
        "id": 430024962,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1711617430
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/stream/348111-std4/topic/RFC.3A.20.60List.2Etake_drop.60.20and.20.60List.2Edrop_take.60/near/430024962\">said</a>:</p>\n<blockquote>\n<p>Ideally (maybe I am being too optimistic or spoiled by isabelle), each of these lemmas is a two liner consisting of one extensionality or induction (maybe functional inductinon) tactic and one closing tactic (<code>by induction … &lt;;&gt; simp_all</code>), so the individual workload should be low.</p>\n</blockquote>\n<p>As one data point, I made <a href=\"https://github.com/leanprover-community/aesop/blob/d09ac8c6526e5d512b73edeea14246be4e4a1c39/AesopTest/List.lean\">a test file for Aesop</a> containing the first 100 lemmas from mathlib3's <code>data.list.basic</code> (this was before Mathlib4 was a thing). With some sensible Aesop rules, ~95% of these lemmas are <code>by aesop</code> or <code>by induction x &lt;;&gt; aesop</code> (and the <code>aesop</code> call often comes down mostly to <code>simp_all</code>).</p>",
        "id": 430038847,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1711622530
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span> Thanks for sharing.  That's good to hear.</p>\n<p>Are the comments such as \"-- attribute [-simp] subset_def\" affecting Aesop by disabling the named lemmas?</p>",
        "id": 430283646,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1711730557
    },
    {
        "content": "<p>This change has caused a breakage in Mathlib. See <a href=\"https://github.com/leanprover-community/mathlib4/pull/11833\">#11833</a>. If anyone is able to take a look that would be great. (This will be needed to release v4.8.0-rc1 and get Mathlib on it.)</p>",
        "id": 430677176,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1712011968
    },
    {
        "content": "<p>The problem is in Mathlib/Combinators/Enumerative/Composition.lean, in <code>get_splitWrtCompositionAux</code>. Perhaps <span class=\"user-mention\" data-user-id=\"110050\">@Sébastien Gouëzel</span> (the author) or <span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span> is able to take a look?</p>",
        "id": 430677422,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1712012090
    },
    {
        "content": "<p>(there's probably no point looking for another hour, since there is no cache yet :) )</p>",
        "id": 430677646,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1712012214
    },
    {
        "content": "<p>Depends on your machine, I guess. :-)</p>\n<p>In any case, I just fixed this, sorry for the noise.</p>",
        "id": 430677810,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1712012310
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110994\">Joe Hendrix</span> <a href=\"#narrow/stream/348111-std4/topic/RFC.3A.20.60List.2Etake_drop.60.20and.20.60List.2Edrop_take.60/near/430283646\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"256311\">Jannis Limperg</span> Thanks for sharing.  That's good to hear.</p>\n<p>Are the comments such as \"-- attribute [-simp] subset_def\" affecting Aesop by disabling the named lemmas?</p>\n</blockquote>\n<p>This test file was originally an evaluation for the Aesop paper. For lemmas that were already ported to Mathlib4 at the time and were tagged <code>@[simp]</code>, I removed the <code>simp</code> attribute so that Aesop wouldn't trivially succeed. For lemmas that weren't tagged <code>@[simp]</code>, I wrote these comments to indicate that I had checked this. But the comments have no effect on Aesop.</p>",
        "id": 431116464,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1712157143
    }
]